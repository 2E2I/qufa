{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공정성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목표\n",
    "\n",
    "* 모델 데이터에서 나타날 수 있는 여러 유형의 편향에 대한 이해도 제고\n",
    "* 모델을 학습시키기 전에 특성 데이터를 살펴보고 잠재적 데이터 편향 요인을 미리 파악\n",
    "* 종합집계하는 대신 하위 그룹으로 묶어 모델 성능을 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개요\n",
    "\n",
    "머신러닝(ML)에 원치 않는 편향이 발생할 수 있는 방식에 주목하면서 *공정성*을 염두에 두고 데이터세트를 살펴보고 분류자를 평가\n",
    "\n",
    "공정성에 관한 ML 프로세스의 컨텍스트를 구성할 기회를 제공하는 **Fairness** 작업을 확인. 작업을 진행하는 동안 편향을 파악하고, 이러한 편향이 해결되지 않을 때 발생하는 모델 예측의 장기적인 영향을 고려"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터세트 및 Prediction 작업 정보\n",
    "서울대학교 보건 데이터셋을 활용\n",
    "\n",
    "\\- 원본 데이터세트에서 ML 공정성에 영향을 미칠 수 있는 field만을 임의 선택하여 학습에 사용\n",
    "\n",
    "### Binary(이진) Features\n",
    "*   `sex`: 성별\n",
    "*   `cva`: 뇌졸중 과거력\n",
    "*   `fcvayn`: 뇌졸중 가족력\n",
    "\n",
    "### Numeric(수적) Features\n",
    "*   `packyear`: 하루 흡연량(갑) X 흡연기간\n",
    "*   `packyear`: 일주일간 음주 빈도\n",
    "*   `exerfq`: 일주일간 운동한 총 일수\n",
    "\n",
    "### Categorical(범주적) Features\n",
    "*   `age`: 나이\n",
    "\n",
    "### Prediction 작업\n",
    "예측 작업은 조사 대상자의 성별을 예측하기 위해 실행\n",
    "\n",
    "### Label\n",
    "*   `sex`: 조사 대상자의 성별을 나타냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공정성 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 균등 기회 (Equal Opportunity)\n",
    "\n",
    "- definition: 보호 그룹과 보호되지 않은 그룹은 동일한 참긍정(True Positive)의 비율을 가져야 함\n",
    "- `sex` field 에서 남녀 성별 확인을 위한 Prediction\n",
    "- Category `cva` 중 Subgroup `0`(뇌졸중 과거력 있음) 입력에 따른 TPR과 Subgroup `1`(뇌졸중 과거력 없음) 입력에 따른 TPR이 같아야만 균등 기회(Equal Opportunity)를 만족"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 균등 승률 (Equalized odds)\n",
    "\n",
    "- definition: 보호된 그룹과 보호되지 않은 그룹은 참긍정(True Positive)과 오탐지(False Negative)에 대해 동일한 비율을 가져야 함\n",
    "- `sex` field 에서 남녀 성별 확인을 위한 Prediction\n",
    "- Category `cva` 중 Subgroup `0`(뇌졸중 과거력 있음) 입력에 따른 TPR, FNR과 Subgroup `1`(뇌졸중 과거력 없음) 입력에 따른 TPR, FNR이 같아야만 균등 승률(Equalized odds)을 만족"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 인구통계패리티 (Demographic Parity)\n",
    "- definition: 긍정적인 결과의 가능성은 개인이 보호된(예 : 여성) 그룹에 있는지 여부 에 관계없이 동일해야 함\n",
    "- `sex` field 에서 남녀 성별 확인을 위한 Prediction\n",
    "- Category `cva` 중 Subgroup `0`(뇌졸중 과거력 있음) 입력에 따른 TP+FP/TN+FN과 Subgroup `1`(뇌졸중 과거력 없음) 입력에 따른 TP+FP/TN+FN이 같아야만 인구통계패리티 (Demographic Parity)을 만족"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S44yNfPhEKzM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import seaborn as sns\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "### target\n",
    "*   `sex`: 조사 대상자의 성별을 나타냄\n",
    "\n",
    "### Subgroup\n",
    "*   `cva`: 뇌졸중 과거력을 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"before.csv\")\n",
    "train.fillna(0, inplace=True)\n",
    "\n",
    "test = pd.read_csv('testset.csv')\n",
    "test.fillna(0, inplace=True)\n",
    "\n",
    "target = 'sex'\n",
    "subgroup = 'cva'\n",
    "\n",
    "col = list(train.columns)\n",
    "except_target = col.copy()\n",
    "except_target.remove(target)\n",
    "lable=target\n",
    "features = list(train.columns)\n",
    "features.remove(lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Knx5pklhGecQ",
    "outputId": "51563b84-7e72-47f7-b49d-6812b751f4b9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train=train[lable].astype(int)\n",
    "X_train=train[features].astype(int)\n",
    "\n",
    "\n",
    "y_test=test[lable].astype(int)\n",
    "X_test=test[features].astype(int)\n",
    "\n",
    "CATEGORY  =  subgroup\n",
    "SUBGROUP = 0 \n",
    "X_test_a  = test.loc[test[CATEGORY] == SUBGROUP][features]\n",
    "y_test_a  = test.loc[test[CATEGORY] == SUBGROUP][lable]\n",
    "\n",
    "SUBGROUP = 1 \n",
    "X_test_b  = test.loc[test[CATEGORY] == SUBGROUP][features]\n",
    "y_test_b  = test.loc[test[CATEGORY] == SUBGROUP][lable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness 작업 #1\n",
    "\n",
    "* 보정 전 데이터셋를 사용하여 `SVC`, `LogisticRegression` 등 모델 학습\n",
    "* 학습 결과에 따른 서브그룹별 TP, TN, FP, FN 도출 및 Confusion Matrix 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(y_test, y_hat) : \n",
    "    \n",
    "    tp = np.sum((y_test ==1) & (y_hat==1) )\n",
    "    tn = np.sum((y_test ==0) & (y_hat==0) )\n",
    "    fp = np.sum((y_test ==0) & (y_hat==1) )\n",
    "    fn = np.sum((y_test ==1) & (y_hat==0) )\n",
    "    \n",
    "    accuracy = np.mean(np.equal(y_test,y_hat))\n",
    "    \n",
    "    return tp, tn, fp, fn, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before TPRA : 0.9326298701298701/ before FPRA : 0.8160406091370558/ before DFA : 0.14370284387695878\n",
      "before TPRB : 0.8611111111111112/ before FPRB : 0.76/ before DFB : 0.23529411764705882\n"
     ]
    }
   ],
   "source": [
    "#model = SVC(kernel = 'rbf')\n",
    "#model = SVC(C=1)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model.predict(X_test_a)\n",
    "tp_a, tn_a, fp_a, fn_a, accuracy = get_info(y_test_a, y_hat)\n",
    "before_tpr_a = tp_a/(tp_a+fn_a)\n",
    "before_fpr_a = fp_a/(fp_a+tn_a)\n",
    "before_dp_a = (tn_a+fn_a)/(tp_a+fp_a)\n",
    "\n",
    "y_hat = model.predict(X_test_b)\n",
    "tp_b, tn_b, fp_b, fn_b, accuracy = get_info(y_test_b, y_hat)\n",
    "before_tpr_b = tp_b/(tp_b+fn_b)\n",
    "before_fpr_b = fp_b/(fp_b+tn_b)\n",
    "before_dp_b = (tn_b+fn_b)/(tp_b+fp_b) \n",
    "\n",
    "print(\"before TPRA : \" + str(before_tpr_a) + \"/ before FPRA : \" + str(before_fpr_a) + \"/ before DFA : \" + str(before_dp_a))\n",
    "print(\"before TPRB : \" + str(before_tpr_b) + \"/ before FPRB : \" + str(before_fpr_b) + \"/ before DFB : \" + str(before_dp_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness 작업 #2\n",
    "\n",
    "* Fairness 작업 #1에서 도출된 서브그룹 별 TPR 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_data( df, cur_col, tpra, tprb ) : \n",
    "    uniq = df[cur_col].unique()\n",
    "    return_li = []\n",
    "    for i in uniq : \n",
    "        return_li.append(df[df[cur_col]==i])\n",
    "\n",
    "    arg_len = len(return_li)\n",
    "    avg_ratio=abs(tpra-tprb)\n",
    "    avg_fair=[]\n",
    "    arg_sum = 0\n",
    "    \n",
    "    for i in range(arg_len) : \n",
    "        arg_sum+=len(return_li[i])\n",
    "    arg_avg = arg_sum/arg_len\n",
    "    \n",
    "    for i in range(arg_len) : \n",
    "        if len(return_li[i])>arg_avg : \n",
    "            avg_fair.append(len(return_li[i])-(len(return_li[i])-arg_avg)*avg_ratio)\n",
    "        else : avg_fair.append(len(return_li[i]))\n",
    "            \n",
    "    return return_li, avg_fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_data( df, cur_col, ratio ) : \n",
    "    uniq = df[cur_col].unique()\n",
    "    return_li = []\n",
    "    for i in uniq : \n",
    "        return_li.append(df[df[cur_col]==i])\n",
    "    arg_avg, avg_fair= get_avg(return_li, ratio)\n",
    "    return return_li, avg_fair\n",
    "\n",
    "def get_avg( arg, ratio ) : \n",
    "    arg_sum = 0\n",
    "    arg_len = len(arg)\n",
    "    avg_ratio=[]\n",
    "    avg_fair=[]\n",
    "    \n",
    "    for i in range(arg_len) : \n",
    "        arg_sum+=(len(arg[i])*ratio)\n",
    "    arg_avg = arg_sum/arg_len\n",
    "        \n",
    "    for i in range(arg_len) : \n",
    "        if len(arg[i])>arg_avg : \n",
    "            avg_fair.append(arg_avg)\n",
    "        else : avg_fair.append(len(arg[i]))\n",
    "            \n",
    "    return arg_avg, avg_fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness(avg_fair, fair_data, col):\n",
    "\n",
    "    tmp_fair_data=[]\n",
    "    tmp_avg_li=[]\n",
    "\n",
    "    for i,j in zip(fair_data,avg_fair) : \n",
    "        if j < len(i) : \n",
    "            ratio=1-((len(i)-j)/len(i))\n",
    "        else : ratio=1\n",
    "        #print(ratio)        \n",
    "        return_li,avg = get_next_data(i, col, ratio)\n",
    "\n",
    "        tmp_avg_li.append(avg)\n",
    "        tmp_fair_data.append(return_li)\n",
    "\n",
    "    tmp_fair_data=list(itertools.chain(*tmp_fair_data))\n",
    "    #print(len(b))\n",
    "\n",
    "    avg_fair=list(itertools.chain(*tmp_avg_li))\n",
    "    \n",
    "    return avg_fair, tmp_fair_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_data, avg_fair = get_first_data(train, target, before_tpr_a, before_tpr_b)\n",
    "for i in except_target : \n",
    "    avg_fair, fair_data = fairness(avg_fair, fair_data, i)\n",
    "\n",
    "fair=pd.DataFrame(columns=col)\n",
    "for i,j in zip(fair_data,avg_fair) :\n",
    "    fair = pd.concat([i.sample(int(j)), fair])\n",
    "    \n",
    "y_fair=fair[lable].astype(int)\n",
    "X_fair=fair[features].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "befor.to_csv(\"before10_14.csv\", index=False)\n",
    "after.to_csv(\"after10_14.csv\", index=False)\n",
    "test.to_csv(\"test10_14.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "datafairness.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
