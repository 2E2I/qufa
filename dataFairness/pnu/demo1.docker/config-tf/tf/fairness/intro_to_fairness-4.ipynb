# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
import tempfile
!pip install seaborn==0.8.1
import seaborn as sns
import itertools
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import precision_recall_curve
from google.colab import widgets
# For facets
from IPython.core.display import display, HTML
import base64
!pip install facets-overview==1.0.0
from facets_overview.feature_statistics_generator import FeatureStatisticsGenerator

import sys

print(tf.__version__)
print('Modules are imported.')

"""
COLUMNS = ["age", "workclass", "fnlwgt", "education", "education_num",
           "marital_status", "occupation", "relationship", "race", "gender",
           "capital_gain", "capital_loss", "hours_per_week", "native_country",
           "income_bracket"]
"""
COLUMNS = ["dayofmonth", "dayofweek", "deptime", "arrtime", "flightnum", "actualelapsedtime", "airtime",
          "arrdelay", "depdelay", "distance", "taxiin", "taxiout", "uniquecarrier", "tailnum", "origin",
          "dest", "calcelled", "cancellationcode", "arrdelay_bracket"]

train_df = pd.read_csv(
    "http://164.125.37.222:18099/data/2008_00-1_train.csv",
    names=COLUMNS,
    sep=r'\s*,\s*',
    engine='python',
    na_values="?")
test_df = pd.read_csv(
    "http://164.125.37.222:18099/data/2008_00-1_test.csv",
    names=COLUMNS,
    sep=r'\s*,\s*',
    skiprows=[0],
    engine='python',
    na_values="?")

# Drop rows with missing values
train_df = train_df.dropna(how="any", axis=0)
test_df = test_df.dropna(how="any", axis=0)

# print('UCI Adult Census Income dataset loaded.')
print('US Airline OnTime Statistics dataset loaded.')

#@title Visualize the Data in Facets
fsg = FeatureStatisticsGenerator()
dataframes = [
    {'table': train_df, 'name': 'trainData'}]
censusProto = fsg.ProtoFromDataFrames(dataframes)
protostr = base64.b64encode(censusProto.SerializeToString()).decode("utf-8")


HTML_TEMPLATE = """<script src="https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js"></script>
        <link rel="import" href="https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html">
        <facets-overview id="elem"></facets-overview>
        <script>
          document.querySelector("#elem").protoInput = "{protostr}";
        </script>"""
html = HTML_TEMPLATE.format(protostr=protostr)
display(HTML(html))

#@title Set the Number of Data Points to Visualize in Facets Dive

SAMPLE_SIZE = 2500 #@param

train_dive = train_df.sample(SAMPLE_SIZE).to_json(orient='records')

HTML_TEMPLATE = """<script src="https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js"></script>
        <link rel="import" href="https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html">
        <facets-dive id="elem" height="600"></facets-dive>
        <script>
          var data = {jsonstr};
          console.log(data);
          document.querySelector("#elem").data = data;
        </script>"""
html = HTML_TEMPLATE.format(jsonstr=train_dive)
display(HTML(html))
# print(html)

# feature = 'capital_gain / capital_loss' #@param ["", "hours_per_week", "fnlwgt", "gender", "capital_gain / capital_loss", "age"] {allow-input: false}
feature = 'taxiin / taxiout'

if feature == "dayofweek":
  print(
'''dayofweek''')
if feature == "origin":
  print(
"""origin""")
if feature == "dest":
  print(
"""dest""")
if feature == "taxiin / taxiout":
  print(
"""taxiin / taxiout""")
if feature == "dayofmonth":
  print(
'''dayofmonth''')

def csv_to_pandas_input_fn(data, batch_size=100, num_epochs=1, shuffle=False):
#   return tf.estimator.inputs.pandas_input_fn(
  return tf.compat.v1.estimator.inputs.pandas_input_fn(
      x=data.drop('arrdelay_bracket', axis=1),
      y=data['arrdelay_bracket'].apply(lambda x: ">10" in x).astype(int),
      batch_size=batch_size,
      num_epochs=num_epochs,
      shuffle=shuffle,
      num_threads=1)

print('csv_to_pandas_input_fn() defined.')

#@title Categorical Feature Columns

# Since we don't know the full range of possible values with occupation and
# native_country, we'll use categorical_column_with_hash_bucket() to help map
# each feature string into an integer ID.
"""
occupation = tf.feature_column.categorical_column_with_hash_bucket(
    "occupation", hash_bucket_size=1000)
native_country = tf.feature_column.categorical_column_with_hash_bucket(
    "native_country", hash_bucket_size=1000)
"""
uniquecarrier = tf.feature_column.categorical_column_with_hash_bucket(
    "uniquecarrier", hash_bucket_size=1000)
tailnum = tf.feature_column.categorical_column_with_hash_bucket(
    "tailnum", hash_bucket_size=1000)
origin = tf.feature_column.categorical_column_with_hash_bucket(
    "origin", hash_bucket_size=1000)
dest = tf.feature_column.categorical_column_with_hash_bucket(
    "dest", hash_bucket_size=1000)


# For the remaining categorical features, since we know what the possible values
# are, we can be more explicit and use categorical_column_with_vocabulary_list()
"""
gender = tf.feature_column.categorical_column_with_vocabulary_list(
    "gender", ["Female", "Male"])
race = tf.feature_column.categorical_column_with_vocabulary_list(
    "race", [
        "White", "Asian-Pac-Islander", "Amer-Indian-Eskimo", "Other", "Black"
    ])
education = tf.feature_column.categorical_column_with_vocabulary_list(
    "education", [
        "Bachelors", "HS-grad", "11th", "Masters", "9th",
        "Some-college", "Assoc-acdm", "Assoc-voc", "7th-8th",
        "Doctorate", "Prof-school", "5th-6th", "10th", "1st-4th",
        "Preschool", "12th"
    ])
marital_status = tf.feature_column.categorical_column_with_vocabulary_list(
    "marital_status", [
        "Married-civ-spouse", "Divorced", "Married-spouse-absent",
        "Never-married", "Separated", "Married-AF-spouse", "Widowed"
    ])
relationship = tf.feature_column.categorical_column_with_vocabulary_list(
    "relationship", [
        "Husband", "Not-in-family", "Wife", "Own-child", "Unmarried",
        "Other-relative"
    ])
workclass = tf.feature_column.categorical_column_with_vocabulary_list(
    "workclass", [
        "Self-emp-not-inc", "Private", "State-gov", "Federal-gov",
        "Local-gov", "?", "Self-emp-inc", "Without-pay", "Never-worked"
    ])
"""
cancelled = tf.feature_column.categorical_column_with_vocabulary_list(
    "cancelled", ["0", "1"])
cancellationcode = tf.feature_column.categorical_column_with_vocabulary_list(
    "cancellationcode", ["A", "B", "C", "N"])

print('Categorical feature columns defined.')

#@title Numeric Feature Columns
# For Numeric features, we can just call on feature_column.numeric_column()
# to use its raw value instead of having to create a map between value and ID.
"""
age = tf.feature_column.numeric_column("age")
fnlwgt = tf.feature_column.numeric_column("fnlwgt")
education_num = tf.feature_column.numeric_column("education_num")
capital_gain = tf.feature_column.numeric_column("capital_gain")
capital_loss = tf.feature_column.numeric_column("capital_loss")
hours_per_week = tf.feature_column.numeric_column("hours_per_week")
"""
dayofmonth = tf.feature_column.numeric_column("dayofmonth")
dayofweek = tf.feature_column.numeric_column("dayofweek")
deptime = tf.feature_column.numeric_column("dayofmodeptimenth")
arrtime = tf.feature_column.numeric_column("arrtime")
flightnum = tf.feature_column.numeric_column("flightnum")
actualelapsedtime = tf.feature_column.numeric_column("actualelapsedtime")
airtime = tf.feature_column.numeric_column("airtime")
arrdelay = tf.feature_column.numeric_column("arrdelay")
depdelay = tf.feature_column.numeric_column("depdelay")
distance = tf.feature_column.numeric_column("distance")
taxiin = tf.feature_column.numeric_column("taxiin")
taxiout = tf.feature_column.numeric_column("taxiout")

print('Numeric feature columns defined.')

"""
age_buckets = tf.feature_column.bucketized_column(
    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])
"""
dayofmonth_buckets = tf.feature_column.bucketized_column(
    dayofmonth, boundaries=[3, 6, 9, 12, 15, 18, 21, 24, 27, 30])

# List of variables, with special handling for gender subgroup.
"""
variables = [native_country, education, occupation, workclass,
             relationship, age_buckets]
"""
variables = [uniquecarrier, tailnum, origin, dest, dayofmonth_buckets]

"""
subgroup_variables = [gender]
"""
subgroup_variables = [cancellationcode]

feature_columns = variables + subgroup_variables


