{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2e_0DJJ8zE29",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "!pip install seaborn==0.8.1\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from google.colab import widgets\n",
    "# For facets\n",
    "from IPython.core.display import display, HTML\n",
    "import base64\n",
    "!pip install facets-overview==1.0.0\n",
    "from facets_overview.feature_statistics_generator import FeatureStatisticsGenerator\n",
    "\n",
    "import sys\n",
    "\n",
    "print(tf.__version__)\n",
    "print('Modules are imported.')\n",
    "\n",
    "\"\"\"\n",
    "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "           \"income_bracket\"]\n",
    "\"\"\"\n",
    "COLUMNS = [\"dayofmonth\", \"dayofweek\", \"deptime\", \"arrtime\", \"flightnum\", \"actualelapsedtime\", \"airtime\",\n",
    "          \"arrdelay\", \"depdelay\", \"distance\", \"taxiin\", \"taxiout\", \"uniquecarrier\", \"tailnum\", \"origin\",\n",
    "          \"dest\", \"calcelled\", \"cancellationcode\", \"arrdelay_bracket\"]\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    \"http://164.125.37.222:18099/data/2008_00-1.csv\",\n",
    "    names=COLUMNS,\n",
    "    sep=r'\\s*,\\s*',\n",
    "    engine='python',\n",
    "    na_values=\"?\")\n",
    "test_df = pd.read_csv(\n",
    "    \"http://164.125.37.222:18099/data/2008_00-1.csv\",\n",
    "    names=COLUMNS,\n",
    "    sep=r'\\s*,\\s*',\n",
    "    skiprows=[0],\n",
    "    engine='python',\n",
    "    na_values=\"?\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "train_df = train_df.dropna(how=\"any\", axis=0)\n",
    "test_df = test_df.dropna(how=\"any\", axis=0)\n",
    "\n",
    "# print('UCI Adult Census Income dataset loaded.')\n",
    "print('US Airline OnTime Statistics dataset loaded.')\n",
    "\n",
    "#@title Visualize the Data in Facets\n",
    "fsg = FeatureStatisticsGenerator()\n",
    "dataframes = [\n",
    "    {'table': train_df, 'name': 'trainData'}]\n",
    "censusProto = fsg.ProtoFromDataFrames(dataframes)\n",
    "protostr = base64.b64encode(censusProto.SerializeToString()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n",
    "        <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n",
    "        <facets-overview id=\"elem\"></facets-overview>\n",
    "        <script>\n",
    "          document.querySelector(\"#elem\").protoInput = \"{protostr}\";\n",
    "        </script>\"\"\"\n",
    "html = HTML_TEMPLATE.format(protostr=protostr)\n",
    "display(HTML(html))\n",
    "\n",
    "#@title Set the Number of Data Points to Visualize in Facets Dive\n",
    "\n",
    "SAMPLE_SIZE = 2500 #@param\n",
    "  \n",
    "train_dive = train_df.sample(SAMPLE_SIZE).to_json(orient='records')\n",
    "\n",
    "HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n",
    "        <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n",
    "        <facets-dive id=\"elem\" height=\"600\"></facets-dive>\n",
    "        <script>\n",
    "          var data = {jsonstr};\n",
    "          console.log(data);\n",
    "          document.querySelector(\"#elem\").data = data;\n",
    "        </script>\"\"\"\n",
    "html = HTML_TEMPLATE.format(jsonstr=train_dive)\n",
    "display(HTML(html))\n",
    "# print(html)\n",
    "\n",
    "\n",
    "# feature = 'capital_gain / capital_loss' #@param [\"\", \"hours_per_week\", \"fnlwgt\", \"gender\", \"capital_gain / capital_loss\", \"age\"] {allow-input: false}\n",
    "feature = 'taxiin / taxiout'\n",
    "\n",
    "if feature == \"dayofweek\":\n",
    "  print(\n",
    "'''dayofweek''')\n",
    "if feature == \"origin\":\n",
    "  print(\n",
    "\"\"\"origin\"\"\")\n",
    "if feature == \"dest\":\n",
    "  print(\n",
    "\"\"\"dest\"\"\")\n",
    "if feature == \"taxiin / taxiout\":\n",
    "  print(\n",
    "\"\"\"taxiin / taxiout\"\"\")\n",
    "if feature == \"dayofmonth\":\n",
    "  print(\n",
    "'''dayofmonth''')\n",
    "\n",
    "\n",
    "def csv_to_pandas_input_fn(data, batch_size=100, num_epochs=1, shuffle=False):\n",
    "#   return tf.estimator.inputs.pandas_input_fn(\n",
    "  return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "      x=data.drop('arrdelay_bracket', axis=1),\n",
    "      y=data['arrdelay_bracket'].apply(lambda x: \">10\" in x).astype(int),\n",
    "      batch_size=batch_size,\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle,\n",
    "      num_threads=1)\n",
    "\n",
    "print('csv_to_pandas_input_fn() defined.')\n",
    "\n",
    "#@title Categorical Feature Columns\n",
    "\n",
    "# Since we don't know the full range of possible values with occupation and\n",
    "# native_country, we'll use categorical_column_with_hash_bucket() to help map\n",
    "# each feature string into an integer ID.\n",
    "\"\"\"\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"occupation\", hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"native_country\", hash_bucket_size=1000)\n",
    "\"\"\"\n",
    "uniquecarrier = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"uniquecarrier\", hash_bucket_size=1000)\n",
    "tailnum = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"tailnum\", hash_bucket_size=1000)\n",
    "origin = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"origin\", hash_bucket_size=1000)\n",
    "dest = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"dest\", hash_bucket_size=1000)\n",
    "\n",
    "\n",
    "# For the remaining categorical features, since we know what the possible values\n",
    "# are, we can be more explicit and use categorical_column_with_vocabulary_list()\n",
    "\"\"\"\n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"gender\", [\"Female\", \"Male\"])\n",
    "race = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"race\", [\n",
    "        \"White\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\", \"Black\"\n",
    "    ])\n",
    "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"education\", [\n",
    "        \"Bachelors\", \"HS-grad\", \"11th\", \"Masters\", \"9th\",\n",
    "        \"Some-college\", \"Assoc-acdm\", \"Assoc-voc\", \"7th-8th\",\n",
    "        \"Doctorate\", \"Prof-school\", \"5th-6th\", \"10th\", \"1st-4th\",\n",
    "        \"Preschool\", \"12th\"\n",
    "    ])\n",
    "marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"marital_status\", [\n",
    "        \"Married-civ-spouse\", \"Divorced\", \"Married-spouse-absent\",\n",
    "        \"Never-married\", \"Separated\", \"Married-AF-spouse\", \"Widowed\"\n",
    "    ])\n",
    "relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"relationship\", [\n",
    "        \"Husband\", \"Not-in-family\", \"Wife\", \"Own-child\", \"Unmarried\",\n",
    "        \"Other-relative\"\n",
    "    ])\n",
    "workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"workclass\", [\n",
    "        \"Self-emp-not-inc\", \"Private\", \"State-gov\", \"Federal-gov\",\n",
    "        \"Local-gov\", \"?\", \"Self-emp-inc\", \"Without-pay\", \"Never-worked\"\n",
    "    ])\n",
    "\"\"\"\n",
    "cancelled = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"cancelled\", [\"0\", \"1\"])\n",
    "cancellationcode = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"cancellationcode\", [\"A\", \"B\", \"C\", \"N\"])\n",
    "\n",
    "print('Categorical feature columns defined.')\n",
    "\n",
    "#@title Numeric Feature Columns\n",
    "# For Numeric features, we can just call on feature_column.numeric_column()\n",
    "# to use its raw value instead of having to create a map between value and ID.\n",
    "\"\"\"\n",
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "fnlwgt = tf.feature_column.numeric_column(\"fnlwgt\")\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")\n",
    "\"\"\"\n",
    "dayofmonth = tf.feature_column.numeric_column(\"dayofmonth\")\n",
    "dayofweek = tf.feature_column.numeric_column(\"dayofweek\")\n",
    "deptime = tf.feature_column.numeric_column(\"dayofmodeptimenth\")\n",
    "arrtime = tf.feature_column.numeric_column(\"arrtime\")\n",
    "flightnum = tf.feature_column.numeric_column(\"flightnum\")\n",
    "actualelapsedtime = tf.feature_column.numeric_column(\"actualelapsedtime\")\n",
    "airtime = tf.feature_column.numeric_column(\"airtime\")\n",
    "arrdelay = tf.feature_column.numeric_column(\"arrdelay\")\n",
    "depdelay = tf.feature_column.numeric_column(\"depdelay\")\n",
    "distance = tf.feature_column.numeric_column(\"distance\")\n",
    "taxiin = tf.feature_column.numeric_column(\"taxiin\")\n",
    "taxiout = tf.feature_column.numeric_column(\"taxiout\")\n",
    "\n",
    "print('Numeric feature columns defined.')\n",
    "\"\"\"\n",
    "age_buckets = tf.feature_column.bucketized_column(\n",
    "    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "\"\"\"\n",
    "dayofmonth_buckets = tf.feature_column.bucketized_column(\n",
    "    dayofmonth, boundaries=[3, 6, 9, 12, 15, 18, 21, 24, 27, 30])\n",
    "\n",
    "# List of variables, with special handling for gender subgroup.\n",
    "\"\"\"\n",
    "variables = [native_country, education, occupation, workclass,\n",
    "             relationship, age_buckets]\n",
    "\"\"\"\n",
    "variables = [uniquecarrier, tailnum, origin, dest, dayofmonth_buckets]\n",
    "\n",
    "\"\"\"\n",
    "subgroup_variables = [gender]\n",
    "\"\"\"\n",
    "subgroup_variables = [cancellationcode]\n",
    "\n",
    "feature_columns = variables + subgroup_variables\n",
    "\n",
    "\"\"\"\n",
    "deep_columns = [\n",
    "    tf.feature_column.indicator_column(workclass),\n",
    "    tf.feature_column.indicator_column(education),\n",
    "    tf.feature_column.indicator_column(age_buckets),\n",
    "    tf.feature_column.indicator_column(gender),\n",
    "    tf.feature_column.indicator_column(relationship),\n",
    "    tf.feature_column.embedding_column(native_country, dimension=8),\n",
    "    tf.feature_column.embedding_column(occupation, dimension=8),\n",
    "]\n",
    "\"\"\"\n",
    "deep_columns = [\n",
    "    tf.feature_column.indicator_column(uniquecarrier),\n",
    "    tf.feature_column.indicator_column(tailnum),\n",
    "    tf.feature_column.indicator_column(dayofmonth_buckets),\n",
    "    tf.feature_column.indicator_column(cancellationcode),\n",
    "    tf.feature_column.embedding_column(origin, dimension=8),\n",
    "    tf.feature_column.embedding_column(dest, dimension=8),\n",
    "]\n",
    "\n",
    "print(deep_columns)\n",
    "print('Deep columns created.')\n",
    "\n",
    "#@title Define Deep Neural Net Model\n",
    "\n",
    "HIDDEN_UNITS = [1024, 512] #@param\n",
    "LEARNING_RATE = 0.1 #@param\n",
    "L1_REGULARIZATION_STRENGTH = 0.0001 #@param\n",
    "L2_REGULARIZATION_STRENGTH = 0.0001 #@param\n",
    "\n",
    "#################################\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#################################\n",
    "\n",
    "model_dir = tempfile.mkdtemp()\n",
    "single_task_deep_model = tf.estimator.DNNClassifier(\n",
    "    feature_columns=deep_columns,\n",
    "    hidden_units=HIDDEN_UNITS,\n",
    "    optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "#     optimizer=tf.compat.v1.train.ProximalAdagradOptimizer(\n",
    "      learning_rate=LEARNING_RATE,\n",
    "      l1_regularization_strength=L1_REGULARIZATION_STRENGTH,\n",
    "      l2_regularization_strength=L2_REGULARIZATION_STRENGTH),\n",
    "    model_dir=model_dir)\n",
    "\n",
    "print('Deep neural net model defined.')\n",
    "\n",
    "#@title Fit Deep Neural Net Model to the Adult Training Dataset\n",
    "\n",
    "STEPS = 1000 #@param\n",
    "\n",
    "single_task_deep_model.train(\n",
    "    input_fn=csv_to_pandas_input_fn(train_df, num_epochs=None, shuffle=True),\n",
    "    steps=STEPS);\n",
    "\n",
    "print('Deep neural net model is done fitting.')\n",
    "\n",
    "#@title Evaluate Deep Neural Net Performance\n",
    "\n",
    "results = single_task_deep_model.evaluate(\n",
    "    input_fn=csv_to_pandas_input_fn(test_df, num_epochs=1, shuffle=False),\n",
    "    steps=None)\n",
    "print(\"model directory = %s\" % model_dir)\n",
    "print(\"---- Results ----\")\n",
    "for key in sorted(results):\n",
    "  print(\"%s: %s\" % (key, results[key]))\n",
    "\n",
    "#@test {\"output\": \"ignore\"}\n",
    "#@title Define Function to Compute Binary Confusion Matrix Evaluation Metrics\n",
    "def compute_eval_metrics(references, predictions):\n",
    "  tn, fp, fn, tp = confusion_matrix(references, predictions).ravel()\n",
    "  precision = tp / float(tp + fp)\n",
    "  recall = tp / float(tp + fn)\n",
    "  false_positive_rate = fp / float(fp + tn)\n",
    "  false_omission_rate = fn / float(tn + fn)\n",
    "  return precision, recall, false_positive_rate, false_omission_rate\n",
    "\n",
    "print('Binary confusion matrix and evaluation metrics defined.')\n",
    "\n",
    "\n",
    "#@title Define Function to Visualize Binary Confusion Matrix\n",
    "def plot_confusion_matrix(confusion_matrix, class_names, figsize = (6,12)):\n",
    "    # We're taking our calculated binary confusion matrix that's already in form \n",
    "    # of an array and turning it into a Pandas DataFrame because it's a lot \n",
    "    # easier to work with when visualizing a heat map in Seaborn.\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Combine the instance (numercial value) with its description\n",
    "    strings = np.asarray([['True Positives', 'False Negatives'],\n",
    "                          ['False Positives', 'True Negatives']])\n",
    "    labels = (np.asarray(\n",
    "        [\"{0:d}\\n{1}\".format(value, string) for string, value in zip(\n",
    "            strings.flatten(), confusion_matrix.flatten())])).reshape(2, 2)\n",
    "\n",
    "    heatmap = sns.heatmap(df_cm, annot=labels, fmt=\"\");\n",
    "    heatmap.yaxis.set_ticklabels(\n",
    "        heatmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "    heatmap.xaxis.set_ticklabels(\n",
    "        heatmap.xaxis.get_ticklabels(), rotation=45, ha='right')\n",
    "    plt.ylabel('References')\n",
    "    plt.xlabel('Predictions')\n",
    "    return fig\n",
    "\n",
    "print('Binary confusion matrix visualization defined.')\n",
    "\n",
    "#@title Visualize Binary Confusion Matrix and Compute Evaluation Metrics Per Subgroup\n",
    "\"\"\"\n",
    "CATEGORY  =  \"gender\" #@param {type:\"string\"}\n",
    "SUBGROUP =  \"Male\" #@param {type:\"string\"}\n",
    "\"\"\"\n",
    "CATEGORY  =  \"cancellationcode\" #@param {type:\"string\"}\n",
    "SUBGROUP =  \"N\" #@param {type:\"string\"}\n",
    "\n",
    "# Given define subgroup, generate predictions and obtain its corresponding \n",
    "# ground truth.\n",
    "predictions_dict = single_task_deep_model.predict(input_fn=csv_to_pandas_input_fn(\n",
    "    test_df.loc[test_df[CATEGORY] == SUBGROUP], num_epochs=1, shuffle=False))\n",
    "predictions = []\n",
    "for prediction_item, in zip(predictions_dict):\n",
    "    predictions.append(prediction_item['class_ids'][0])\n",
    "actuals = list(\n",
    "    test_df.loc[test_df[CATEGORY] == SUBGROUP]['arrdelay_bracket'].apply(\n",
    "        lambda x: '>10' in x).astype(int))\n",
    "classes = ['Over 10min', 'Less than 10min']\n",
    "\n",
    "# To stay consistent, we have to flip the confusion \n",
    "# matrix around on both axes because sklearn's confusion matrix module by\n",
    "# default is rotated.\n",
    "rotated_confusion_matrix = np.fliplr(confusion_matrix(actuals, predictions))\n",
    "rotated_confusion_matrix = np.flipud(rotated_confusion_matrix)\n",
    "\n",
    "tb = widgets.TabBar(['Confusion Matrix', 'Evaluation Metrics'], location='top')\n",
    "\n",
    "with tb.output_to('Confusion Matrix'):\n",
    "  plot_confusion_matrix(rotated_confusion_matrix, classes);\n",
    "\n",
    "with tb.output_to('Evaluation Metrics'):\n",
    "  grid = widgets.Grid(2,4)\n",
    "\n",
    "  p, r, fpr, fomr = compute_eval_metrics(actuals, predictions)\n",
    "\n",
    "  with grid.output_to(0, 0):\n",
    "    print(' Precision ')\n",
    "  with grid.output_to(1, 0):\n",
    "    print(' %.4f ' % p)\n",
    "\n",
    "  with grid.output_to(0, 1):\n",
    "    print(' Recall ')\n",
    "  with grid.output_to(1, 1):\n",
    "    print(' %.4f ' % r)\n",
    "\n",
    "  with grid.output_to(0, 2):\n",
    "    print(' False Positive Rate ')\n",
    "  with grid.output_to(1, 2):\n",
    "    print(' %.4f ' % fpr)\n",
    "\n",
    "  with grid.output_to(0, 3):\n",
    "    print(' False Omission Rate ')\n",
    "  with grid.output_to(1, 3):\n",
    "    print(' %.4f ' % fomr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KlF-lQ8yQ69b",
    "qZ-9vJgSEpHj",
    "TF3B5h3c-7Fb"
   ],
   "name": "intro_to_fairness.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
