{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHpbnneJYcwJ"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2e_0DJJ8zE29"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "!pip install seaborn==0.8.1\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from google.colab import widgets\n",
    "# For facets\n",
    "from IPython.core.display import display, HTML\n",
    "import base64\n",
    "!pip install facets-overview==1.0.0\n",
    "from facets_overview.feature_statistics_generator import FeatureStatisticsGenerator\n",
    "\n",
    "print('Modules are imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TeCNVvVUVS0P"
   },
   "outputs": [],
   "source": [
    "COLUMNS = [\"dep\",\"arr\",\"date\",\"amount\",\"income_bracket\"]\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    \"/tf/data/sample-1.csv\",\n",
    "    names=COLUMNS,\n",
    "    sep=r'\\s*,\\s*',\n",
    "    engine='python',\n",
    "    na_values=\"?\")\n",
    "test_df = pd.read_csv(\n",
    "    \"/tf/data/sample-1.csv\",\n",
    "    names=COLUMNS,\n",
    "    sep=r'\\s*,\\s*',\n",
    "    skiprows=[0],\n",
    "    engine='python',\n",
    "    na_values=\"?\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "train_df = train_df.dropna(how=\"any\", axis=0)\n",
    "test_df = test_df.dropna(how=\"any\", axis=0)\n",
    "\n",
    "print('UCI Adult Census Income dataset loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "MW-qryqs1gig"
   },
   "outputs": [],
   "source": [
    "#@title Visualize the Data in Facets\n",
    "fsg = FeatureStatisticsGenerator()\n",
    "dataframes = [\n",
    "    {'table': train_df, 'name': 'trainData'}]\n",
    "censusProto = fsg.ProtoFromDataFrames(dataframes)\n",
    "protostr = base64.b64encode(censusProto.SerializeToString()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n",
    "        <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n",
    "        <facets-overview id=\"elem\"></facets-overview>\n",
    "        <script>\n",
    "          document.querySelector(\"#elem\").protoInput = \"{protostr}\";\n",
    "        </script>\"\"\"\n",
    "html = HTML_TEMPLATE.format(protostr=protostr)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "stlklrG_xssF"
   },
   "outputs": [],
   "source": [
    "#@title Set the Number of Data Points to Visualize in Facets Dive\n",
    "\n",
    "SAMPLE_SIZE = 30 #@param\n",
    "  \n",
    "train_dive = train_df.sample(SAMPLE_SIZE).to_json(orient='records')\n",
    "\n",
    "HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n",
    "        <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n",
    "        <facets-dive id=\"elem\" height=\"600\"></facets-dive>\n",
    "        <script>\n",
    "          var data = {jsonstr};\n",
    "          document.querySelector(\"#elem\").data = data;\n",
    "        </script>\"\"\"\n",
    "html = HTML_TEMPLATE.format(jsonstr=train_dive)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "8bFDVCV1sxiX"
   },
   "outputs": [],
   "source": [
    "# feature = 'capital_gain / capital_loss' #@param [\"\", \"hours_per_week\", \"fnlwgt\", \"gender\", \"capital_gain / capital_loss\", \"age\"] {allow-input: false}\n",
    "feature = 'amount' #@param[\"source\", \"target\", \"date\", \"amount\"]\n",
    "\n",
    "if feature == \"dep\":\n",
    "  print(\n",
    "'''feature: dep''')\n",
    "if feature == \"arr\":\n",
    "  print(\n",
    "\"\"\"feature: arr\"\"\")\n",
    "if feature == \"date\":\n",
    "  print(\n",
    "\"\"\"feature: date\"\"\")\n",
    "if feature == \"amount\":\n",
    "  print(\n",
    "\"\"\"feature: amount\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bt-rQvJLx4Hm"
   },
   "outputs": [],
   "source": [
    "def csv_to_pandas_input_fn(data, batch_size=100, num_epochs=1, shuffle=False):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "      x=data.drop('income_bracket', axis=1),\n",
    "      y=data['income_bracket'].apply(lambda x: \">5K\" in x).astype(int),\n",
    "      batch_size=batch_size,\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle,\n",
    "      num_threads=1)\n",
    "\n",
    "print('csv_to_pandas_input_fn() defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "tAG5hUJwx725"
   },
   "outputs": [],
   "source": [
    "#@title Categorical Feature Columns\n",
    "\n",
    "# Since we don't know the full range of possible values with occupation and\n",
    "# native_country, we'll use categorical_column_with_hash_bucket() to help map\n",
    "# each feature string into an integer ID.\n",
    "# date = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#     \"date\", hash_bucket_size=1000)\n",
    "# amount = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#     \"amount\", hash_bucket_size=1000)\n",
    "\n",
    "# For the remaining categorical features, since we know what the possible values\n",
    "# are, we can be more explicit and use categorical_column_with_vocabulary_list()\n",
    "dep = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"dep\", [\"Seoul\"])\n",
    "arr = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"arr\", [\"Chunan\"])\n",
    "\n",
    "print('Categorical feature columns defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Jwtuu8MmyKCJ"
   },
   "outputs": [],
   "source": [
    "#@title Numeric Feature Columns\n",
    "# For Numeric features, we can just call on feature_column.numeric_column()\n",
    "# to use its raw value instead of having to create a map between value and ID.\n",
    "date = tf.feature_column.numeric_column(\"date\")\n",
    "amount = tf.feature_column.numeric_column(\"amount\")\n",
    "\n",
    "print('Numeric feature columns defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HxVm8X15yLR7"
   },
   "outputs": [],
   "source": [
    "date_buckets = tf.feature_column.bucketized_column(\n",
    "    date, boundaries=[5, 10, 15, 20, 25, 30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O68xV_24gbnD"
   },
   "outputs": [],
   "source": [
    "# List of variables, with special handling for gender subgroup.\n",
    "variables = [dep]\n",
    "subgroup_variables = []\n",
    "feature_columns = variables + subgroup_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "bnyw4cyLTSUB"
   },
   "outputs": [],
   "source": [
    "deep_columns = [\n",
    "    tf.feature_column.indicator_column(dep),\n",
    "    tf.feature_column.indicator_column(arr),\n",
    "    tf.feature_column.indicator_column(date_buckets),\n",
    "    tf.feature_column.indicator_column(amount),\n",
    "#     tf.feature_column.embedding_column(date, dimension=8),\n",
    "]\n",
    "\n",
    "print(deep_columns)\n",
    "print('Deep columns created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "tQZ1kumWk8XO"
   },
   "outputs": [],
   "source": [
    "#@title Define Deep Neural Net Model\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "HIDDEN_UNITS = [1024, 512] #@param\n",
    "LEARNING_RATE = 0.1 #@param\n",
    "L1_REGULARIZATION_STRENGTH = 0.0001 #@param\n",
    "L2_REGULARIZATION_STRENGTH = 0.0001 #@param\n",
    "\n",
    "model_dir = tempfile.mkdtemp()\n",
    "single_task_deep_model = tf.estimator.DNNClassifier(\n",
    "    feature_columns=deep_columns,\n",
    "    hidden_units=HIDDEN_UNITS,\n",
    "    optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "      learning_rate=LEARNING_RATE,\n",
    "      l1_regularization_strength=L1_REGULARIZATION_STRENGTH,\n",
    "      l2_regularization_strength=L2_REGULARIZATION_STRENGTH),\n",
    "    model_dir=model_dir)\n",
    "\n",
    "print('Deep neural net model defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "UtrhAXwvqtVD",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@title Fit Deep Neural Net Model to the Adult Training Dataset\n",
    "\n",
    "STEPS = 1000 #@param\n",
    "\n",
    "single_task_deep_model.train(\n",
    "    input_fn=csv_to_pandas_input_fn(train_df, num_epochs=None, shuffle=True),\n",
    "    steps=STEPS);\n",
    "\n",
    "print('Deep neural net model is done fitting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "HDV8hYqvncCy"
   },
   "outputs": [],
   "source": [
    "#@title Evaluate Deep Neural Net Performance\n",
    "\n",
    "results = single_task_deep_model.evaluate(\n",
    "    input_fn=csv_to_pandas_input_fn(test_df, num_epochs=1, shuffle=False),\n",
    "    steps=None)\n",
    "print(\"model directory = %s\" % model_dir)\n",
    "print(\"---- Results ----\")\n",
    "for key in sorted(results):\n",
    "  print(\"%s: %s\" % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "CmOWym53VITS"
   },
   "outputs": [],
   "source": [
    "#@test {\"output\": \"ignore\"}\n",
    "#@title Define Function to Compute Binary Confusion Matrix Evaluation Metrics\n",
    "def compute_eval_metrics(references, predictions):\n",
    "  tn, fp, fn, tp = confusion_matrix(references, predictions).ravel()\n",
    "  precision = tp / float(tp + fp)\n",
    "  recall = tp / float(tp + fn)\n",
    "  false_positive_rate = fp / float(fp + tn)\n",
    "  false_omission_rate = fn / float(tn + fn)\n",
    "  return precision, recall, false_positive_rate, false_omission_rate\n",
    "\n",
    "print('Binary confusion matrix and evaluation metrics defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "TMIN_nl1VFuS"
   },
   "outputs": [],
   "source": [
    "#@title Define Function to Visualize Binary Confusion Matrix\n",
    "def plot_confusion_matrix(confusion_matrix, class_names, figsize = (8,6)):\n",
    "    # We're taking our calculated binary confusion matrix that's already in form \n",
    "    # of an array and turning it into a Pandas DataFrame because it's a lot \n",
    "    # easier to work with when visualizing a heat map in Seaborn.\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Combine the instance (numercial value) with its description\n",
    "    strings = np.asarray([['True Positives', 'False Negatives'],\n",
    "                          ['False Positives', 'True Negatives']])\n",
    "    labels = (np.asarray(\n",
    "        [\"{0:d}\\n{1}\".format(value, string) for string, value in zip(\n",
    "            strings.flatten(), confusion_matrix.flatten())])).reshape(2, 2)\n",
    "\n",
    "    heatmap = sns.heatmap(df_cm, annot=labels, fmt=\"\");\n",
    "    heatmap.yaxis.set_ticklabels(\n",
    "        heatmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "    heatmap.xaxis.set_ticklabels(\n",
    "        heatmap.xaxis.get_ticklabels(), rotation=45, ha='right')\n",
    "    plt.ylabel('References')\n",
    "    plt.xlabel('Predictions')\n",
    "    return fig\n",
    "\n",
    "print('Binary confusion matrix visualization defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "5TBzaWs1VKTa"
   },
   "outputs": [],
   "source": [
    "#@title Visualize Binary Confusion Matrix and Compute Evaluation Metrics Per Subgroup\n",
    "CATEGORY  =  \"dep\" #@param {type:\"string\"}\n",
    "SUBGROUP =  \"Seoul\" #@param {type:\"string\"}\n",
    "\n",
    "# Given define subgroup, generate predictions and obtain its corresponding \n",
    "# ground truth.\n",
    "predictions_dict = single_task_deep_model.predict(input_fn=csv_to_pandas_input_fn(\n",
    "    test_df.loc[test_df[CATEGORY] == SUBGROUP], num_epochs=1, shuffle=False))\n",
    "predictions = []\n",
    "for prediction_item, in zip(predictions_dict):\n",
    "    predictions.append(prediction_item['class_ids'][0])\n",
    "actuals = list(\n",
    "    test_df.loc[test_df[CATEGORY] == SUBGROUP]['income_bracket'].apply(\n",
    "        lambda x: '>5K' in x).astype(int))\n",
    "classes = ['Over 5K', 'Less than 5K']\n",
    "\n",
    "# To stay consistent, we have to flip the confusion \n",
    "# matrix around on both axes because sklearn's confusion matrix module by\n",
    "# default is rotated.\n",
    "rotated_confusion_matrix = np.fliplr(confusion_matrix(actuals, predictions))\n",
    "rotated_confusion_matrix = np.flipud(rotated_confusion_matrix)\n",
    "\n",
    "tb = widgets.TabBar(['Confusion Matrix', 'Evaluation Metrics'], location='top')\n",
    "\n",
    "with tb.output_to('Confusion Matrix'):\n",
    "  plot_confusion_matrix(rotated_confusion_matrix, classes);\n",
    "\n",
    "with tb.output_to('Evaluation Metrics'):\n",
    "  grid = widgets.Grid(2,4)\n",
    "\n",
    "  p, r, fpr, fomr = compute_eval_metrics(actuals, predictions)\n",
    "\n",
    "  with grid.output_to(0, 0):\n",
    "    print(' Precision ')\n",
    "  with grid.output_to(1, 0):\n",
    "    print(' %.4f ' % p)\n",
    "\n",
    "  with grid.output_to(0, 1):\n",
    "    print(' Recall ')\n",
    "  with grid.output_to(1, 1):\n",
    "    print(' %.4f ' % r)\n",
    "\n",
    "  with grid.output_to(0, 2):\n",
    "    print(' False Positive Rate ')\n",
    "  with grid.output_to(1, 2):\n",
    "    print(' %.4f ' % fpr)\n",
    "\n",
    "  with grid.output_to(0, 3):\n",
    "    print(' False Omission Rate ')\n",
    "  with grid.output_to(1, 3):\n",
    "    print(' %.4f ' % fomr)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KlF-lQ8yQ69b",
    "qZ-9vJgSEpHj",
    "TF3B5h3c-7Fb"
   ],
   "name": "intro_to_fairness.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
