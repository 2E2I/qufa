{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_A152Tiz9_k"
   },
   "source": [
    "## 셀프 어텐션 모델 기반 정형 데이터 결측치 보간 기법\n",
    "\n",
    "- 본 연구는 수치형/범주형 변수가 혼합되어 있는 정형 데이터를 대상으로 결측값 보간 (Missing Value Imputation)을 위한 셀프 어텐션(Self-Attention) 기반 딥러닝 모델을 제안함\n",
    "\n",
    "keyword: 머신러닝, 딥러닝, 데이터품질, 결측값, 데이터정제, 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeJ5_2Cd0LAi"
   },
   "source": [
    "### gpu 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1640670911691,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "wgOWn0TqRIiS",
    "outputId": "c1a34e74-a6c5-443d-e852-c0afb1509858",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 28 18:24:16 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 471.41       Driver Version: 471.41       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   32C    P8     9W / 170W |    443MiB / 12288MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1196    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      3392    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      4960    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5352    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      5564    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      5588    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      9120    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      9600    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI9pOIsB0Pgx"
   },
   "source": [
    "### 소스 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3421,
     "status": "ok",
     "timestamp": 1640670915108,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "tWiF9Pv7SYK0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from dsan import MVIDataset\n",
    "from dsan import Imputer as DSANImputer\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1640670915108,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "bntkqO49W7If"
   },
   "outputs": [],
   "source": [
    "class CategoryMapper(object):\n",
    "    def __init__(self, data, num_vars, cat_vars):\n",
    "        self.data = data\n",
    "        self.num_vars = num_vars\n",
    "        self.cat_vars = cat_vars\n",
    "        self.columns = data.columns\n",
    "        self.label_encoders = defaultdict(LabelEncoder)\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        missing = pd.isnull(data.iloc[:, self.cat_vars])\n",
    "        encode_values = data.iloc[:, self.cat_vars].fillna('NULL')\n",
    "        encode_values = encode_values.astype('str')\n",
    "        encode_values = encode_values.apply(\n",
    "                lambda x: self.label_encoders[x.name].fit_transform(x)\n",
    "                )\n",
    "        encode_values = encode_values.values.astype('float')\n",
    "        encode_values[missing] = np.nan\n",
    "        data.iloc[:, self.cat_vars] = encode_values\n",
    "        return data\n",
    "\n",
    "    def fit(self, data):\n",
    "        missing = pd.isnull(data.iloc[:, self.cat_vars])\n",
    "        encode_values = data.iloc[:, self.cat_vars].fillna('NULL')\n",
    "        encode_values = encode_values.apply(\n",
    "                lambda x: self.label_encoders[x.name].fit(x)\n",
    "                )\n",
    "        \n",
    "    def transform(self, data):\n",
    "        missing = pd.isnull(data.iloc[:, self.cat_vars])\n",
    "        encode_values = data.iloc[:, self.cat_vars].fillna('NULL')\n",
    "        encode_values = encode_values.apply(\n",
    "                lambda x: self.label_encoders[x.name].transform(x)\n",
    "                )\n",
    "        encode_values = encode_values.values.astype('float')\n",
    "        encode_values[missing] = np.nan\n",
    "        data.iloc[:, self.cat_vars] = encode_values\n",
    "        return data\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        data = pd.DataFrame(data, columns=self.columns)\n",
    "        inverse_values = data.iloc[:, self.cat_vars].astype('int')\n",
    "        inverse_values = inverse_values.apply(\n",
    "                lambda x: self.label_encoders[x.name].inverse_transform(x)\n",
    "                ) \n",
    "        data.iloc[:, self.cat_vars] = inverse_values.values\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1640670915109,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "LWCc07SdmapP"
   },
   "outputs": [],
   "source": [
    "def keras_classifier(df, test_idxs):\n",
    "    df['heart_risk10'] = np.where(df['heart_risk10'] < 0.3, 0, 1)\n",
    "    feature_columns = [tf.feature_column.numeric_column(col) for col in df.columns[:-1]]\n",
    "\n",
    "    def create_ds(df, trainset=True):\n",
    "        df = df.copy()\n",
    "        labels = df.pop('heart_risk10')\n",
    "        if trainset:\n",
    "            return tf.data.Dataset.from_tensor_slices((dict(df), labels)).shuffle(buffer_size=len(df)).batch(32)\n",
    "        else:\n",
    "            return tf.data.Dataset.from_tensor_slices((dict(df), labels)).batch(32)\n",
    "    \n",
    "    n_sample = df.shape[0]\n",
    "    train_idxs = sorted(set(range(n_sample)) - set(test_idxs))\n",
    "    train = df.loc[train_idxs, :]\n",
    "    test = df.loc[test_idxs, :]\n",
    "\n",
    "    train_ds = create_ds(train)\n",
    "    test_ds = create_ds(test, trainset=False)\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(feature_columns = feature_columns),\n",
    "    tf.keras.layers.Dense(units=128,activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=128,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=test_ds, epochs=5, use_multiprocessing=True)\n",
    "    \n",
    "    predictions = model.predict(test_ds)\n",
    "    bin_predictions = tf.round(predictions).numpy().flatten()\n",
    "\n",
    "    acc = accuracy_score(test['heart_risk10'].values, bin_predictions)\n",
    "    f1 = f1_score(test['heart_risk10'].values, bin_predictions)\n",
    "    \n",
    "    print('### Confusion Matrix ###')\n",
    "    print(confusion_matrix(test['heart_risk10'].values, bin_predictions))\n",
    "    print(classification_report(test['heart_risk10'].values,bin_predictions))\n",
    "\n",
    "    print(f'Accuracy: {round(acc, 4)}')\n",
    "    print(f'F1 Score: {round(f1, 4)}')\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1640670915109,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "mhWimIDFlC3O"
   },
   "outputs": [],
   "source": [
    "def count_mvs(data):\n",
    "    na_count = data.isnull().sum().sum()\n",
    "    total_count = data.shape[0] * data.shape[1]\n",
    "    missing_rate = round(na_count / total_count * 100, 4)\n",
    "    print(f'Total Missing Values: {na_count}')\n",
    "    print(f'Missing percent: {missing_rate} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnWuCQxoztaL"
   },
   "source": [
    "### 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1518,
     "status": "ok",
     "timestamp": 1640670916621,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "VNIvQr74ip8S"
   },
   "outputs": [],
   "source": [
    "seed = 128\n",
    "set_seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "data = pd.read_csv('./data/health_raw.csv')\n",
    "data = data.iloc[:, 1:]\n",
    "\n",
    "num_vars = data.dtypes[data.dtypes == 'float'].index\n",
    "num_vars = [data.columns.get_loc(idx) for idx in num_vars]\n",
    "num_vars.append(1)\n",
    "num_vars.append(84)\n",
    "num_vars.sort()\n",
    "\n",
    "n_col = data.shape[1]\n",
    "cat_vars = list(set(range(n_col)) - set(num_vars))\n",
    "columns = data.columns\n",
    "\n",
    "n_sample = data.shape[0]\n",
    "n_test = int(0.2 * n_sample)\n",
    "test_idxs = sorted(random.sample(range(n_sample), n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of records:  101500\n",
      "num of columns:  98\n"
     ]
    }
   ],
   "source": [
    "print('num of records: ', data.shape[0])\n",
    "print('num of columns: ', data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1640670916621,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "p1acpBMkkfqn",
    "outputId": "b76ddb61-ea56-405f-be0d-b0ec212b5e12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cva</th>\n",
       "      <th>htn</th>\n",
       "      <th>lip</th>\n",
       "      <th>dm</th>\n",
       "      <th>dep</th>\n",
       "      <th>schizo</th>\n",
       "      <th>bipol</th>\n",
       "      <th>anx</th>\n",
       "      <th>insom</th>\n",
       "      <th>alch</th>\n",
       "      <th>stress</th>\n",
       "      <th>asth2</th>\n",
       "      <th>fhtnyn</th>\n",
       "      <th>fcvayn</th>\n",
       "      <th>flipyn</th>\n",
       "      <th>fbipolyn</th>\n",
       "      <th>fschizoyn</th>\n",
       "      <th>fanxyn</th>\n",
       "      <th>finsomyn</th>\n",
       "      <th>falchyn</th>\n",
       "      <th>fstressyn</th>\n",
       "      <th>fdepyn</th>\n",
       "      <th>fdmyn</th>\n",
       "      <th>fasthyn</th>\n",
       "      <th>jb_irelay</th>\n",
       "      <th>sd_idr2</th>\n",
       "      <th>sd_idr3</th>\n",
       "      <th>income</th>\n",
       "      <th>edu</th>\n",
       "      <th>Coffee</th>\n",
       "      <th>coff_sugar</th>\n",
       "      <th>coff_cream</th>\n",
       "      <th>greentea</th>\n",
       "      <th>softdrink</th>\n",
       "      <th>etcdrink</th>\n",
       "      <th>menyn</th>\n",
       "      <th>hrtyn</th>\n",
       "      <th>exerfq</th>\n",
       "      <th>DXA_total_tscore</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>FVC</th>\n",
       "      <th>FEV1</th>\n",
       "      <th>FEF25_75</th>\n",
       "      <th>PEF</th>\n",
       "      <th>FVC__exp</th>\n",
       "      <th>FEV1__exp</th>\n",
       "      <th>FEF25_75__exp</th>\n",
       "      <th>PEF__exp</th>\n",
       "      <th>Imp_muscle</th>\n",
       "      <th>Imp_fat</th>\n",
       "      <th>hsCRP</th>\n",
       "      <th>FBS</th>\n",
       "      <th>FBInsulin</th>\n",
       "      <th>Hb_A1c</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>rGTP</th>\n",
       "      <th>UricAcid</th>\n",
       "      <th>TSH</th>\n",
       "      <th>tCholesterol</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>WBC</th>\n",
       "      <th>RBC</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Platelet</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Waist</th>\n",
       "      <th>Hip</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>ces_dep</th>\n",
       "      <th>marry_yn</th>\n",
       "      <th>snoring_yn</th>\n",
       "      <th>smoker_yn</th>\n",
       "      <th>DRINK_yn</th>\n",
       "      <th>walk</th>\n",
       "      <th>packyear</th>\n",
       "      <th>calorie_intake</th>\n",
       "      <th>carbo_intake</th>\n",
       "      <th>lipid_intake</th>\n",
       "      <th>lipid_plant</th>\n",
       "      <th>lipid_animal</th>\n",
       "      <th>prot_intake</th>\n",
       "      <th>fiber_intake</th>\n",
       "      <th>bmi</th>\n",
       "      <th>lung_risk10</th>\n",
       "      <th>colo_risk10</th>\n",
       "      <th>dia_risk10</th>\n",
       "      <th>heart_risk10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.2</td>\n",
       "      <td>40.8</td>\n",
       "      <td>62.8</td>\n",
       "      <td>41.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>323.8</td>\n",
       "      <td>155.9</td>\n",
       "      <td>64.4</td>\n",
       "      <td>69.8</td>\n",
       "      <td>85.6</td>\n",
       "      <td>67.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>554.6</td>\n",
       "      <td>309.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.094320</td>\n",
       "      <td>0.175325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>110.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>182.1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>122.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>493.0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>69.6</td>\n",
       "      <td>82.2</td>\n",
       "      <td>90.4</td>\n",
       "      <td>126.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>382.8</td>\n",
       "      <td>85.4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163458</td>\n",
       "      <td>0.336127</td>\n",
       "      <td>0.160429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8.4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>42.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>123.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>217.7</td>\n",
       "      <td>64.6</td>\n",
       "      <td>133.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>221.6</td>\n",
       "      <td>155.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>64.4</td>\n",
       "      <td>84.6</td>\n",
       "      <td>140.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1131.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>88.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>71.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.081590</td>\n",
       "      <td>0.123890</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.260328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>171.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>50.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>316.8</td>\n",
       "      <td>177.9</td>\n",
       "      <td>66.3</td>\n",
       "      <td>74.6</td>\n",
       "      <td>96.6</td>\n",
       "      <td>124.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3516.8</td>\n",
       "      <td>633.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>32.2</td>\n",
       "      <td>73.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.103175</td>\n",
       "      <td>0.236204</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>237.7</td>\n",
       "      <td>44.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>174.0</td>\n",
       "      <td>190.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>93.4</td>\n",
       "      <td>100.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.4</td>\n",
       "      <td>246.6</td>\n",
       "      <td>142.4</td>\n",
       "      <td>17.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>100.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.026066</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.345936</td>\n",
       "      <td>0.084718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  cva  htn  lip  dm  dep  schizo  bipol  anx  insom  alch  stress  \\\n",
       "0    2   29    1    2    1   1    1       1      1    1      1     1       1   \n",
       "1    2   37    1    1    1   1    1       1      1    1      1     1       2   \n",
       "2    2   32    1    1    1   1    1       1      1    1      1     1       1   \n",
       "3    1   20    1    1    1   1    1       1      1    1      1     1       1   \n",
       "4    1   29    1    1    1   1    1       1      1    1      1     1       1   \n",
       "\n",
       "   asth2  fhtnyn  fcvayn  flipyn  fbipolyn  fschizoyn  fanxyn  finsomyn  \\\n",
       "0      1       1       1       1         1          1       1         1   \n",
       "1      1       2       1       1         1          1       1         1   \n",
       "2      1       2       1       1         1          1       1         1   \n",
       "3      1       1       1       1         1          1       1         1   \n",
       "4      2       2       1       1         1          1       1         1   \n",
       "\n",
       "   falchyn  fstressyn  fdepyn  fdmyn  fasthyn  jb_irelay  sd_idr2  sd_idr3  \\\n",
       "0        1          1       1      2        1          1      NaN      NaN   \n",
       "1        1          1       1      1        1          1      2.0      5.0   \n",
       "2        1          1       1      1        1          1      1.0      3.0   \n",
       "3        1          1       1      1        2          1      1.0      3.0   \n",
       "4        1          1       1      1        1          1      NaN      NaN   \n",
       "\n",
       "   income   edu  Coffee  coff_sugar  coff_cream  greentea  softdrink  \\\n",
       "0     NaN  13.0     1.3         1.7         1.1       NaN        0.2   \n",
       "1   600.0  11.0     0.8         1.1         0.5       NaN        1.1   \n",
       "2   176.0  19.0     1.3         1.0         0.2       0.6        NaN   \n",
       "3     NaN  12.0     NaN         NaN         NaN       NaN        1.5   \n",
       "4   336.0  13.0     0.7         NaN         NaN       1.0        1.0   \n",
       "\n",
       "   etcdrink  menyn  hrtyn  exerfq  DXA_total_tscore  HeartRate  FVC  FEV1  \\\n",
       "0       NaN      2      1     3.0               NaN       56.0  4.0   3.2   \n",
       "1       NaN      1      1     NaN               1.4       61.0  4.8   3.0   \n",
       "2       0.6      1      1     NaN               0.4       89.0  3.4   2.2   \n",
       "3       NaN      1      1     NaN               NaN       72.0  NaN   NaN   \n",
       "4       0.9      1      1     NaN               2.8       85.0  NaN   NaN   \n",
       "\n",
       "   FEF25_75  PEF  FVC__exp  FEV1__exp  FEF25_75__exp  PEF__exp  Imp_muscle  \\\n",
       "0       3.4  6.2      90.0       99.0          132.0      80.0        13.1   \n",
       "1       4.0  6.2     100.0       76.0           66.0     120.0        23.9   \n",
       "2       4.4  8.4     119.0      129.0           35.0      55.0        42.3   \n",
       "3       NaN  NaN       NaN        NaN            NaN       NaN        40.6   \n",
       "4       NaN  NaN       NaN        NaN            NaN       NaN        24.6   \n",
       "\n",
       "   Imp_fat  hsCRP    FBS  FBInsulin  Hb_A1c  Protein  Albumin  Creatinine  \\\n",
       "0      9.7    2.0   86.0        2.6     5.5      8.7      5.5         0.8   \n",
       "1     12.5    0.6  110.0       11.3     5.9      7.5      4.7         1.2   \n",
       "2      9.5    4.4  123.0        8.4     NaN      7.6      4.5         0.4   \n",
       "3     11.4    8.0  120.0       13.0     4.3      8.3      5.0         1.2   \n",
       "4      2.1    3.2  105.0        6.6     5.0      6.5      4.4         1.0   \n",
       "\n",
       "   Calcium   AST   ALT  rGTP  UricAcid  TSH  tCholesterol   HDL    LDL  \\\n",
       "0     10.8  10.0   9.0  39.6       5.5  1.0         191.2  40.8   62.8   \n",
       "1      8.8  12.0  21.0  11.2       4.6  4.0         182.1  35.0   49.2   \n",
       "2     10.3  22.0  15.0  18.2       3.2  1.2         217.7  64.6  133.2   \n",
       "3     10.0  25.0  19.0  31.6       8.3  1.8         171.4  80.0   63.0   \n",
       "4      9.2  47.0  21.0  19.4       7.1  0.4         237.7  44.6   31.8   \n",
       "\n",
       "   triglyceride  WBC  RBC  Hemoglobin  Platelet  Height  Weight  Waist    Hip  \\\n",
       "0          41.8  6.6  5.2        12.0     323.8   155.9    64.4   69.8   85.6   \n",
       "1         122.2  4.2  3.8         8.8     493.0   166.7    69.6   82.2   90.4   \n",
       "2          18.6  9.6  4.2        12.8     221.6   155.1    43.8   64.4   84.6   \n",
       "3          50.4  8.2  5.6        14.8     316.8   177.9    66.3   74.6   96.6   \n",
       "4           NaN  5.4  4.4        16.2     174.0   190.5    77.7   93.4  100.8   \n",
       "\n",
       "     SBP   DBP  ces_dep  marry_yn  snoring_yn  smoker_yn  DRINK_yn   walk  \\\n",
       "0   67.0  65.0     25.0         2           2          1         1   1800   \n",
       "1  126.0  82.0      9.0         2           2          1         2  16200   \n",
       "2  140.0  82.0     19.0         2           1          1         2   1800   \n",
       "3  124.0  79.0     11.0         1           1          2         2   6000   \n",
       "4   98.0  76.0     20.0         1           1          1         1   1800   \n",
       "\n",
       "   packyear  calorie_intake  carbo_intake  lipid_intake  lipid_plant  \\\n",
       "0       NaN           554.6         309.6          31.8         14.0   \n",
       "1       NaN          1335.0         382.8          85.4         39.0   \n",
       "2       NaN          1131.2          41.0          88.4          0.2   \n",
       "3      99.0          3516.8         633.6           2.6          3.4   \n",
       "4       NaN            71.4         246.6         142.4         17.6   \n",
       "\n",
       "   lipid_animal  prot_intake  fiber_intake   bmi  lung_risk10  colo_risk10  \\\n",
       "0           8.0         47.0           8.6  26.4     0.000000     0.011559   \n",
       "1          30.4         47.0          65.2  25.0     0.000000     0.163458   \n",
       "2          41.0         71.8           3.6  18.2     0.081590     0.123890   \n",
       "3          32.2         73.0          14.0  21.0     0.103175     0.236204   \n",
       "4          24.6        100.8          18.6  21.4     0.026066     0.007025   \n",
       "\n",
       "   dia_risk10  heart_risk10  \n",
       "0    0.094320      0.175325  \n",
       "1    0.336127      0.160429  \n",
       "2    0.163300      0.260328  \n",
       "3    0.179487      0.242424  \n",
       "4    0.345936      0.084718  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovda_RWTzhia"
   },
   "source": [
    "### 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1640670916622,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "AiyqeoZgkhJ6",
    "outputId": "b435b57a-35be-47c8-b132-58968bfa50f3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    column name: sd_idr2 \n",
      "    missing values: 37731\n",
      "    missing percent: 37.1734 %\n",
      "    \n",
      "\n",
      "    column name: sd_idr3 \n",
      "    missing values: 37731\n",
      "    missing percent: 37.1734 %\n",
      "    \n",
      "\n",
      "    column name: income \n",
      "    missing values: 9570\n",
      "    missing percent: 9.4286 %\n",
      "    \n",
      "\n",
      "    column name: edu \n",
      "    missing values: 261\n",
      "    missing percent: 0.2571 %\n",
      "    \n",
      "\n",
      "    column name: Coffee \n",
      "    missing values: 13891\n",
      "    missing percent: 13.6857 %\n",
      "    \n",
      "\n",
      "    column name: coff_sugar \n",
      "    missing values: 33118\n",
      "    missing percent: 32.6286 %\n",
      "    \n",
      "\n",
      "    column name: coff_cream \n",
      "    missing values: 42659\n",
      "    missing percent: 42.0286 %\n",
      "    \n",
      "\n",
      "    column name: greentea \n",
      "    missing values: 31581\n",
      "    missing percent: 31.1143 %\n",
      "    \n",
      "\n",
      "    column name: softdrink \n",
      "    missing values: 47299\n",
      "    missing percent: 46.6 %\n",
      "    \n",
      "\n",
      "    column name: etcdrink \n",
      "    missing values: 35148\n",
      "    missing percent: 34.6286 %\n",
      "    \n",
      "\n",
      "    column name: exerfq \n",
      "    missing values: 66990\n",
      "    missing percent: 66.0 %\n",
      "    \n",
      "\n",
      "    column name: DXA_total_tscore \n",
      "    missing values: 1740\n",
      "    missing percent: 1.7143 %\n",
      "    \n",
      "\n",
      "    column name: HeartRate \n",
      "    missing values: 377\n",
      "    missing percent: 0.3714 %\n",
      "    \n",
      "\n",
      "    column name: FVC \n",
      "    missing values: 1044\n",
      "    missing percent: 1.0286 %\n",
      "    \n",
      "\n",
      "    column name: FEV1 \n",
      "    missing values: 1044\n",
      "    missing percent: 1.0286 %\n",
      "    \n",
      "\n",
      "    column name: FEF25_75 \n",
      "    missing values: 1073\n",
      "    missing percent: 1.0571 %\n",
      "    \n",
      "\n",
      "    column name: PEF \n",
      "    missing values: 1073\n",
      "    missing percent: 1.0571 %\n",
      "    \n",
      "\n",
      "    column name: FVC__exp \n",
      "    missing values: 1044\n",
      "    missing percent: 1.0286 %\n",
      "    \n",
      "\n",
      "    column name: FEV1__exp \n",
      "    missing values: 1044\n",
      "    missing percent: 1.0286 %\n",
      "    \n",
      "\n",
      "    column name: FEF25_75__exp \n",
      "    missing values: 1073\n",
      "    missing percent: 1.0571 %\n",
      "    \n",
      "\n",
      "    column name: PEF__exp \n",
      "    missing values: 1073\n",
      "    missing percent: 1.0571 %\n",
      "    \n",
      "\n",
      "    column name: Imp_muscle \n",
      "    missing values: 27318\n",
      "    missing percent: 26.9143 %\n",
      "    \n",
      "\n",
      "    column name: Imp_fat \n",
      "    missing values: 27318\n",
      "    missing percent: 26.9143 %\n",
      "    \n",
      "\n",
      "    column name: hsCRP \n",
      "    missing values: 87\n",
      "    missing percent: 0.0857 %\n",
      "    \n",
      "\n",
      "    column name: FBS \n",
      "    missing values: 261\n",
      "    missing percent: 0.2571 %\n",
      "    \n",
      "\n",
      "    column name: FBInsulin \n",
      "    missing values: 203\n",
      "    missing percent: 0.2 %\n",
      "    \n",
      "\n",
      "    column name: Hb_A1c \n",
      "    missing values: 45733\n",
      "    missing percent: 45.0571 %\n",
      "    \n",
      "\n",
      "    column name: Protein \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n",
      "\n",
      "    column name: Albumin \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n",
      "\n",
      "    column name: Creatinine \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n",
      "\n",
      "    column name: Calcium \n",
      "    missing values: 116\n",
      "    missing percent: 0.1143 %\n",
      "    \n",
      "\n",
      "    column name: AST \n",
      "    missing values: 232\n",
      "    missing percent: 0.2286 %\n",
      "    \n",
      "\n",
      "    column name: ALT \n",
      "    missing values: 261\n",
      "    missing percent: 0.2571 %\n",
      "    \n",
      "\n",
      "    column name: rGTP \n",
      "    missing values: 551\n",
      "    missing percent: 0.5429 %\n",
      "    \n",
      "\n",
      "    column name: UricAcid \n",
      "    missing values: 203\n",
      "    missing percent: 0.2 %\n",
      "    \n",
      "\n",
      "    column name: TSH \n",
      "    missing values: 203\n",
      "    missing percent: 0.2 %\n",
      "    \n",
      "\n",
      "    column name: tCholesterol \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n",
      "\n",
      "    column name: HDL \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n",
      "\n",
      "    column name: LDL \n",
      "    missing values: 348\n",
      "    missing percent: 0.3429 %\n",
      "    \n",
      "\n",
      "    column name: triglyceride \n",
      "    missing values: 638\n",
      "    missing percent: 0.6286 %\n",
      "    \n",
      "\n",
      "    column name: WBC \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n",
      "\n",
      "    column name: RBC \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n",
      "\n",
      "    column name: Hemoglobin \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n",
      "\n",
      "    column name: Platelet \n",
      "    missing values: 87\n",
      "    missing percent: 0.0857 %\n",
      "    \n",
      "\n",
      "    column name: Height \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n",
      "\n",
      "    column name: Weight \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n",
      "\n",
      "    column name: Waist \n",
      "    missing values: 87\n",
      "    missing percent: 0.0857 %\n",
      "    \n",
      "\n",
      "    column name: Hip \n",
      "    missing values: 174\n",
      "    missing percent: 0.1714 %\n",
      "    \n",
      "\n",
      "    column name: SBP \n",
      "    missing values: 290\n",
      "    missing percent: 0.2857 %\n",
      "    \n",
      "\n",
      "    column name: DBP \n",
      "    missing values: 290\n",
      "    missing percent: 0.2857 %\n",
      "    \n",
      "\n",
      "    column name: ces_dep \n",
      "    missing values: 1711\n",
      "    missing percent: 1.6857 %\n",
      "    \n",
      "\n",
      "    column name: packyear \n",
      "    missing values: 79715\n",
      "    missing percent: 78.5369 %\n",
      "    \n",
      "\n",
      "    column name: bmi \n",
      "    missing values: 58\n",
      "    missing percent: 0.0571 %\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "na_idx = (data.isnull().sum() != 0)\n",
    "n_record = data.shape[0]\n",
    "for col, na_c in data.isnull().sum()[na_idx].items():\n",
    "    print(f\"\"\"\n",
    "    column name: {col} \n",
    "    missing values: {na_c}\n",
    "    missing percent: {round(na_c/n_record * 100, 4)} %\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1640670916985,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "RhBwDqMvmjTV",
    "outputId": "a074e3b5-84e3-47b9-9610-5f9576f9fc54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missing Values: 553028\n",
      "Missing percent: 5.5597 %\n"
     ]
    }
   ],
   "source": [
    "count_mvs(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRrVv-QpzkeJ"
   },
   "source": [
    "### 통계량 imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1640670916986,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "COMKyjLdmrun"
   },
   "outputs": [],
   "source": [
    "# statistic imputation\n",
    "class StatImputer(object):\n",
    "    def __init__(self): \n",
    "        return\n",
    "\n",
    "    def fit_transform(self, X_incomplete, cat_vars):\n",
    "        vars = set(range(X_incomplete.shape[1]))\n",
    "        num_vars = list(vars - set(cat_vars))\n",
    "\n",
    "        df = pd.DataFrame(X_incomplete)\n",
    "        means = df.iloc[:, num_vars].mean()\n",
    "        df.fillna(value=means, inplace=True)\n",
    "\n",
    "        modes = df.iloc[:, cat_vars].mode()\n",
    "        mode_dict = dict()\n",
    "        for v in cat_vars:\n",
    "            mode_dict[v] = modes[v][0]\n",
    "        df.fillna(value=mode_dict, inplace=True)\n",
    "        return df.values\n",
    "\n",
    "imputer = StatImputer()\n",
    "X_stat = imputer.fit_transform(data.values, cat_vars=cat_vars)\n",
    "df_stat = pd.DataFrame(X_stat, columns=columns)\n",
    "df_stat.iloc[:, cat_vars] = df_stat.iloc[:, cat_vars].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1640670917885,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "dsGmYRncmO50",
    "outputId": "3c2e6125-b467-48aa-c2af-79576dc1da0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cva</th>\n",
       "      <th>htn</th>\n",
       "      <th>lip</th>\n",
       "      <th>dm</th>\n",
       "      <th>dep</th>\n",
       "      <th>schizo</th>\n",
       "      <th>bipol</th>\n",
       "      <th>anx</th>\n",
       "      <th>insom</th>\n",
       "      <th>alch</th>\n",
       "      <th>stress</th>\n",
       "      <th>asth2</th>\n",
       "      <th>fhtnyn</th>\n",
       "      <th>fcvayn</th>\n",
       "      <th>flipyn</th>\n",
       "      <th>fbipolyn</th>\n",
       "      <th>fschizoyn</th>\n",
       "      <th>fanxyn</th>\n",
       "      <th>finsomyn</th>\n",
       "      <th>falchyn</th>\n",
       "      <th>fstressyn</th>\n",
       "      <th>fdepyn</th>\n",
       "      <th>fdmyn</th>\n",
       "      <th>fasthyn</th>\n",
       "      <th>jb_irelay</th>\n",
       "      <th>sd_idr2</th>\n",
       "      <th>sd_idr3</th>\n",
       "      <th>income</th>\n",
       "      <th>edu</th>\n",
       "      <th>Coffee</th>\n",
       "      <th>coff_sugar</th>\n",
       "      <th>coff_cream</th>\n",
       "      <th>greentea</th>\n",
       "      <th>softdrink</th>\n",
       "      <th>etcdrink</th>\n",
       "      <th>menyn</th>\n",
       "      <th>hrtyn</th>\n",
       "      <th>exerfq</th>\n",
       "      <th>DXA_total_tscore</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>FVC</th>\n",
       "      <th>FEV1</th>\n",
       "      <th>FEF25_75</th>\n",
       "      <th>PEF</th>\n",
       "      <th>FVC__exp</th>\n",
       "      <th>FEV1__exp</th>\n",
       "      <th>FEF25_75__exp</th>\n",
       "      <th>PEF__exp</th>\n",
       "      <th>Imp_muscle</th>\n",
       "      <th>Imp_fat</th>\n",
       "      <th>hsCRP</th>\n",
       "      <th>FBS</th>\n",
       "      <th>FBInsulin</th>\n",
       "      <th>Hb_A1c</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>rGTP</th>\n",
       "      <th>UricAcid</th>\n",
       "      <th>TSH</th>\n",
       "      <th>tCholesterol</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>WBC</th>\n",
       "      <th>RBC</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Platelet</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Waist</th>\n",
       "      <th>Hip</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>ces_dep</th>\n",
       "      <th>marry_yn</th>\n",
       "      <th>snoring_yn</th>\n",
       "      <th>smoker_yn</th>\n",
       "      <th>DRINK_yn</th>\n",
       "      <th>walk</th>\n",
       "      <th>packyear</th>\n",
       "      <th>calorie_intake</th>\n",
       "      <th>carbo_intake</th>\n",
       "      <th>lipid_intake</th>\n",
       "      <th>lipid_plant</th>\n",
       "      <th>lipid_animal</th>\n",
       "      <th>prot_intake</th>\n",
       "      <th>fiber_intake</th>\n",
       "      <th>bmi</th>\n",
       "      <th>lung_risk10</th>\n",
       "      <th>colo_risk10</th>\n",
       "      <th>dia_risk10</th>\n",
       "      <th>heart_risk10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.371387</td>\n",
       "      <td>4.480296</td>\n",
       "      <td>382.945274</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.050181</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.970616</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.463549</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>13.1</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.2</td>\n",
       "      <td>40.8</td>\n",
       "      <td>62.8</td>\n",
       "      <td>41.800000</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>323.8</td>\n",
       "      <td>155.9</td>\n",
       "      <td>64.4</td>\n",
       "      <td>69.8</td>\n",
       "      <td>85.6</td>\n",
       "      <td>67.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>316.169979</td>\n",
       "      <td>554.6</td>\n",
       "      <td>309.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.094320</td>\n",
       "      <td>0.175325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.050181</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.970616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.198551</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>23.9</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>110.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>182.1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>122.200000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>493.0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>69.6</td>\n",
       "      <td>82.2</td>\n",
       "      <td>90.4</td>\n",
       "      <td>126.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>316.169979</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>382.8</td>\n",
       "      <td>85.4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163458</td>\n",
       "      <td>0.336127</td>\n",
       "      <td>0.160429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.979266</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.198551</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>42.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>123.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.467276</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>217.7</td>\n",
       "      <td>64.6</td>\n",
       "      <td>133.2</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>221.6</td>\n",
       "      <td>155.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>64.4</td>\n",
       "      <td>84.6</td>\n",
       "      <td>140.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>316.169979</td>\n",
       "      <td>1131.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>88.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>71.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.081590</td>\n",
       "      <td>0.123890</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.260328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>382.945274</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.087215</td>\n",
       "      <td>0.853694</td>\n",
       "      <td>0.822666</td>\n",
       "      <td>1.050181</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.970616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.198551</td>\n",
       "      <td>1.463549</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.667602</td>\n",
       "      <td>2.954633</td>\n",
       "      <td>3.105509</td>\n",
       "      <td>7.310154</td>\n",
       "      <td>98.557767</td>\n",
       "      <td>103.733017</td>\n",
       "      <td>93.520318</td>\n",
       "      <td>105.912085</td>\n",
       "      <td>40.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>8.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>171.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>50.400000</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>316.8</td>\n",
       "      <td>177.9</td>\n",
       "      <td>66.3</td>\n",
       "      <td>74.6</td>\n",
       "      <td>96.6</td>\n",
       "      <td>124.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>3516.8</td>\n",
       "      <td>633.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>32.2</td>\n",
       "      <td>73.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.103175</td>\n",
       "      <td>0.236204</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.371387</td>\n",
       "      <td>4.480296</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.853694</td>\n",
       "      <td>0.822666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.198551</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3.667602</td>\n",
       "      <td>2.954633</td>\n",
       "      <td>3.105509</td>\n",
       "      <td>7.310154</td>\n",
       "      <td>98.557767</td>\n",
       "      <td>103.733017</td>\n",
       "      <td>93.520318</td>\n",
       "      <td>105.912085</td>\n",
       "      <td>24.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>237.7</td>\n",
       "      <td>44.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>121.903341</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>174.0</td>\n",
       "      <td>190.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>93.4</td>\n",
       "      <td>100.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>316.169979</td>\n",
       "      <td>71.4</td>\n",
       "      <td>246.6</td>\n",
       "      <td>142.4</td>\n",
       "      <td>17.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>100.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.026066</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.345936</td>\n",
       "      <td>0.084718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex   age  cva  htn  lip   dm  dep  schizo  bipol  anx  insom  alch  \\\n",
       "0  2.0  29.0  1.0  2.0  1.0  1.0  1.0     1.0    1.0  1.0    1.0   1.0   \n",
       "1  2.0  37.0  1.0  1.0  1.0  1.0  1.0     1.0    1.0  1.0    1.0   1.0   \n",
       "2  2.0  32.0  1.0  1.0  1.0  1.0  1.0     1.0    1.0  1.0    1.0   1.0   \n",
       "3  1.0  20.0  1.0  1.0  1.0  1.0  1.0     1.0    1.0  1.0    1.0   1.0   \n",
       "4  1.0  29.0  1.0  1.0  1.0  1.0  1.0     1.0    1.0  1.0    1.0   1.0   \n",
       "\n",
       "   stress  asth2  fhtnyn  fcvayn  flipyn  fbipolyn  fschizoyn  fanxyn  \\\n",
       "0     1.0    1.0     1.0     1.0     1.0       1.0        1.0     1.0   \n",
       "1     2.0    1.0     2.0     1.0     1.0       1.0        1.0     1.0   \n",
       "2     1.0    1.0     2.0     1.0     1.0       1.0        1.0     1.0   \n",
       "3     1.0    1.0     1.0     1.0     1.0       1.0        1.0     1.0   \n",
       "4     1.0    2.0     2.0     1.0     1.0       1.0        1.0     1.0   \n",
       "\n",
       "   finsomyn  falchyn  fstressyn  fdepyn  fdmyn  fasthyn  jb_irelay   sd_idr2  \\\n",
       "0       1.0      1.0        1.0     1.0    2.0      1.0        1.0  1.371387   \n",
       "1       1.0      1.0        1.0     1.0    1.0      1.0        1.0  2.000000   \n",
       "2       1.0      1.0        1.0     1.0    1.0      1.0        1.0  1.000000   \n",
       "3       1.0      1.0        1.0     1.0    1.0      2.0        1.0  1.000000   \n",
       "4       1.0      1.0        1.0     1.0    1.0      1.0        1.0  1.371387   \n",
       "\n",
       "    sd_idr3      income   edu    Coffee  coff_sugar  coff_cream  greentea  \\\n",
       "0  4.480296  382.945274  13.0  1.300000    1.700000    1.100000  1.050181   \n",
       "1  5.000000  600.000000  11.0  0.800000    1.100000    0.500000  1.050181   \n",
       "2  3.000000  176.000000  19.0  1.300000    1.000000    0.200000  0.600000   \n",
       "3  3.000000  382.945274  12.0  1.087215    0.853694    0.822666  1.050181   \n",
       "4  4.480296  336.000000  13.0  0.700000    0.853694    0.822666  1.000000   \n",
       "\n",
       "   softdrink  etcdrink  menyn  hrtyn    exerfq  DXA_total_tscore  HeartRate  \\\n",
       "0   0.200000  0.970616    2.0    1.0  3.000000          1.463549       56.0   \n",
       "1   1.100000  0.970616    1.0    1.0  4.198551          1.400000       61.0   \n",
       "2   0.979266  0.600000    1.0    1.0  4.198551          0.400000       89.0   \n",
       "3   1.500000  0.970616    1.0    1.0  4.198551          1.463549       72.0   \n",
       "4   1.000000  0.900000    1.0    1.0  4.198551          2.800000       85.0   \n",
       "\n",
       "        FVC      FEV1  FEF25_75       PEF    FVC__exp   FEV1__exp  \\\n",
       "0  4.000000  3.200000  3.400000  6.200000   90.000000   99.000000   \n",
       "1  4.800000  3.000000  4.000000  6.200000  100.000000   76.000000   \n",
       "2  3.400000  2.200000  4.400000  8.400000  119.000000  129.000000   \n",
       "3  3.667602  2.954633  3.105509  7.310154   98.557767  103.733017   \n",
       "4  3.667602  2.954633  3.105509  7.310154   98.557767  103.733017   \n",
       "\n",
       "   FEF25_75__exp    PEF__exp  Imp_muscle  Imp_fat  hsCRP    FBS  FBInsulin  \\\n",
       "0     132.000000   80.000000        13.1      9.7    2.0   86.0        2.6   \n",
       "1      66.000000  120.000000        23.9     12.5    0.6  110.0       11.3   \n",
       "2      35.000000   55.000000        42.3      9.5    4.4  123.0        8.4   \n",
       "3      93.520318  105.912085        40.6     11.4    8.0  120.0       13.0   \n",
       "4      93.520318  105.912085        24.6      2.1    3.2  105.0        6.6   \n",
       "\n",
       "     Hb_A1c  Protein  Albumin  Creatinine  Calcium   AST   ALT  rGTP  \\\n",
       "0  5.500000      8.7      5.5         0.8     10.8  10.0   9.0  39.6   \n",
       "1  5.900000      7.5      4.7         1.2      8.8  12.0  21.0  11.2   \n",
       "2  5.467276      7.6      4.5         0.4     10.3  22.0  15.0  18.2   \n",
       "3  4.300000      8.3      5.0         1.2     10.0  25.0  19.0  31.6   \n",
       "4  5.000000      6.5      4.4         1.0      9.2  47.0  21.0  19.4   \n",
       "\n",
       "   UricAcid  TSH  tCholesterol   HDL    LDL  triglyceride  WBC  RBC  \\\n",
       "0       5.5  1.0         191.2  40.8   62.8     41.800000  6.6  5.2   \n",
       "1       4.6  4.0         182.1  35.0   49.2    122.200000  4.2  3.8   \n",
       "2       3.2  1.2         217.7  64.6  133.2     18.600000  9.6  4.2   \n",
       "3       8.3  1.8         171.4  80.0   63.0     50.400000  8.2  5.6   \n",
       "4       7.1  0.4         237.7  44.6   31.8    121.903341  5.4  4.4   \n",
       "\n",
       "   Hemoglobin  Platelet  Height  Weight  Waist    Hip    SBP   DBP  ces_dep  \\\n",
       "0        12.0     323.8   155.9    64.4   69.8   85.6   67.0  65.0     25.0   \n",
       "1         8.8     493.0   166.7    69.6   82.2   90.4  126.0  82.0      9.0   \n",
       "2        12.8     221.6   155.1    43.8   64.4   84.6  140.0  82.0     19.0   \n",
       "3        14.8     316.8   177.9    66.3   74.6   96.6  124.0  79.0     11.0   \n",
       "4        16.2     174.0   190.5    77.7   93.4  100.8   98.0  76.0     20.0   \n",
       "\n",
       "   marry_yn  snoring_yn  smoker_yn  DRINK_yn     walk    packyear  \\\n",
       "0       2.0         2.0        1.0       1.0   1800.0  316.169979   \n",
       "1       2.0         2.0        1.0       2.0  16200.0  316.169979   \n",
       "2       2.0         1.0        1.0       2.0   1800.0  316.169979   \n",
       "3       1.0         1.0        2.0       2.0   6000.0   99.000000   \n",
       "4       1.0         1.0        1.0       1.0   1800.0  316.169979   \n",
       "\n",
       "   calorie_intake  carbo_intake  lipid_intake  lipid_plant  lipid_animal  \\\n",
       "0           554.6         309.6          31.8         14.0           8.0   \n",
       "1          1335.0         382.8          85.4         39.0          30.4   \n",
       "2          1131.2          41.0          88.4          0.2          41.0   \n",
       "3          3516.8         633.6           2.6          3.4          32.2   \n",
       "4            71.4         246.6         142.4         17.6          24.6   \n",
       "\n",
       "   prot_intake  fiber_intake   bmi  lung_risk10  colo_risk10  dia_risk10  \\\n",
       "0         47.0           8.6  26.4     0.000000     0.011559    0.094320   \n",
       "1         47.0          65.2  25.0     0.000000     0.163458    0.336127   \n",
       "2         71.8           3.6  18.2     0.081590     0.123890    0.163300   \n",
       "3         73.0          14.0  21.0     0.103175     0.236204    0.179487   \n",
       "4        100.8          18.6  21.4     0.026066     0.007025    0.345936   \n",
       "\n",
       "   heart_risk10  \n",
       "0      0.175325  \n",
       "1      0.160429  \n",
       "2      0.260328  \n",
       "3      0.242424  \n",
       "4      0.084718  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1640670917886,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "uUrL9IKemU4T",
    "outputId": "4a62fe0f-0d43-47e2-ca25-2c4f8ee7073a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missing Values: 0\n",
      "Missing percent: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "count_mvs(df_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 154228,
     "status": "ok",
     "timestamp": 1640671072108,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "v5_pwG_gu9_8",
    "outputId": "1f90a0d0-3f8a-49c2-ba2f-2925b6f46bed",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'IteratorGetNext:89' shape=(None,) dtype=float64>, 'age': <tf.Tensor 'IteratorGetNext:37' shape=(None,) dtype=float64>, 'cva': <tf.Tensor 'IteratorGetNext:49' shape=(None,) dtype=float64>, 'htn': <tf.Tensor 'IteratorGetNext:72' shape=(None,) dtype=float64>, 'lip': <tf.Tensor 'IteratorGetNext:76' shape=(None,) dtype=float64>, 'dm': <tf.Tensor 'IteratorGetNext:52' shape=(None,) dtype=float64>, 'dep': <tf.Tensor 'IteratorGetNext:50' shape=(None,) dtype=float64>, 'schizo': <tf.Tensor 'IteratorGetNext:86' shape=(None,) dtype=float64>, 'bipol': <tf.Tensor 'IteratorGetNext:41' shape=(None,) dtype=float64>, 'anx': <tf.Tensor 'IteratorGetNext:39' shape=(None,) dtype=float64>, 'insom': <tf.Tensor 'IteratorGetNext:74' shape=(None,) dtype=float64>, 'alch': <tf.Tensor 'IteratorGetNext:38' shape=(None,) dtype=float64>, 'stress': <tf.Tensor 'IteratorGetNext:93' shape=(None,) dtype=float64>, 'asth2': <tf.Tensor 'IteratorGetNext:40' shape=(None,) dtype=float64>, 'fhtnyn': <tf.Tensor 'IteratorGetNext:63' shape=(None,) dtype=float64>, 'fcvayn': <tf.Tensor 'IteratorGetNext:60' shape=(None,) dtype=float64>, 'flipyn': <tf.Tensor 'IteratorGetNext:66' shape=(None,) dtype=float64>, 'fbipolyn': <tf.Tensor 'IteratorGetNext:59' shape=(None,) dtype=float64>, 'fschizoyn': <tf.Tensor 'IteratorGetNext:67' shape=(None,) dtype=float64>, 'fanxyn': <tf.Tensor 'IteratorGetNext:57' shape=(None,) dtype=float64>, 'finsomyn': <tf.Tensor 'IteratorGetNext:65' shape=(None,) dtype=float64>, 'falchyn': <tf.Tensor 'IteratorGetNext:56' shape=(None,) dtype=float64>, 'fstressyn': <tf.Tensor 'IteratorGetNext:68' shape=(None,) dtype=float64>, 'fdepyn': <tf.Tensor 'IteratorGetNext:61' shape=(None,) dtype=float64>, 'fdmyn': <tf.Tensor 'IteratorGetNext:62' shape=(None,) dtype=float64>, 'fasthyn': <tf.Tensor 'IteratorGetNext:58' shape=(None,) dtype=float64>, 'jb_irelay': <tf.Tensor 'IteratorGetNext:75' shape=(None,) dtype=float64>, 'sd_idr2': <tf.Tensor 'IteratorGetNext:87' shape=(None,) dtype=float64>, 'sd_idr3': <tf.Tensor 'IteratorGetNext:88' shape=(None,) dtype=float64>, 'income': <tf.Tensor 'IteratorGetNext:73' shape=(None,) dtype=float64>, 'edu': <tf.Tensor 'IteratorGetNext:53' shape=(None,) dtype=float64>, 'Coffee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'coff_sugar': <tf.Tensor 'IteratorGetNext:47' shape=(None,) dtype=float64>, 'coff_cream': <tf.Tensor 'IteratorGetNext:46' shape=(None,) dtype=float64>, 'greentea': <tf.Tensor 'IteratorGetNext:69' shape=(None,) dtype=float64>, 'softdrink': <tf.Tensor 'IteratorGetNext:92' shape=(None,) dtype=float64>, 'etcdrink': <tf.Tensor 'IteratorGetNext:54' shape=(None,) dtype=float64>, 'menyn': <tf.Tensor 'IteratorGetNext:82' shape=(None,) dtype=float64>, 'hrtyn': <tf.Tensor 'IteratorGetNext:70' shape=(None,) dtype=float64>, 'exerfq': <tf.Tensor 'IteratorGetNext:55' shape=(None,) dtype=float64>, 'DXA_total_tscore': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'HeartRate': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, 'FVC': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'FEV1': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'FEF25_75': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'PEF': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float64>, 'FVC__exp': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'FEV1__exp': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'FEF25_75__exp': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'PEF__exp': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'Imp_muscle': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'Imp_fat': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=float64>, 'hsCRP': <tf.Tensor 'IteratorGetNext:71' shape=(None,) dtype=float64>, 'FBS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'FBInsulin': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'Hb_A1c': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, 'Protein': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float64>, 'Albumin': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'Creatinine': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'Calcium': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'AST': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'ALT': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'rGTP': <tf.Tensor 'IteratorGetNext:85' shape=(None,) dtype=float64>, 'UricAcid': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float64>, 'TSH': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float64>, 'tCholesterol': <tf.Tensor 'IteratorGetNext:94' shape=(None,) dtype=float64>, 'HDL': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'LDL': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float64>, 'triglyceride': <tf.Tensor 'IteratorGetNext:95' shape=(None,) dtype=float64>, 'WBC': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float64>, 'RBC': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float64>, 'Hemoglobin': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float64>, 'Platelet': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'Height': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, 'Weight': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float64>, 'Waist': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float64>, 'Hip': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'SBP': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float64>, 'DBP': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'ces_dep': <tf.Tensor 'IteratorGetNext:45' shape=(None,) dtype=float64>, 'marry_yn': <tf.Tensor 'IteratorGetNext:81' shape=(None,) dtype=float64>, 'snoring_yn': <tf.Tensor 'IteratorGetNext:91' shape=(None,) dtype=float64>, 'smoker_yn': <tf.Tensor 'IteratorGetNext:90' shape=(None,) dtype=float64>, 'DRINK_yn': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'walk': <tf.Tensor 'IteratorGetNext:96' shape=(None,) dtype=float64>, 'packyear': <tf.Tensor 'IteratorGetNext:83' shape=(None,) dtype=float64>, 'calorie_intake': <tf.Tensor 'IteratorGetNext:43' shape=(None,) dtype=float64>, 'carbo_intake': <tf.Tensor 'IteratorGetNext:44' shape=(None,) dtype=float64>, 'lipid_intake': <tf.Tensor 'IteratorGetNext:78' shape=(None,) dtype=float64>, 'lipid_plant': <tf.Tensor 'IteratorGetNext:79' shape=(None,) dtype=float64>, 'lipid_animal': <tf.Tensor 'IteratorGetNext:77' shape=(None,) dtype=float64>, 'prot_intake': <tf.Tensor 'IteratorGetNext:84' shape=(None,) dtype=float64>, 'fiber_intake': <tf.Tensor 'IteratorGetNext:64' shape=(None,) dtype=float64>, 'bmi': <tf.Tensor 'IteratorGetNext:42' shape=(None,) dtype=float64>, 'lung_risk10': <tf.Tensor 'IteratorGetNext:80' shape=(None,) dtype=float64>, 'colo_risk10': <tf.Tensor 'IteratorGetNext:48' shape=(None,) dtype=float64>, 'dia_risk10': <tf.Tensor 'IteratorGetNext:51' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'IteratorGetNext:89' shape=(None,) dtype=float64>, 'age': <tf.Tensor 'IteratorGetNext:37' shape=(None,) dtype=float64>, 'cva': <tf.Tensor 'IteratorGetNext:49' shape=(None,) dtype=float64>, 'htn': <tf.Tensor 'IteratorGetNext:72' shape=(None,) dtype=float64>, 'lip': <tf.Tensor 'IteratorGetNext:76' shape=(None,) dtype=float64>, 'dm': <tf.Tensor 'IteratorGetNext:52' shape=(None,) dtype=float64>, 'dep': <tf.Tensor 'IteratorGetNext:50' shape=(None,) dtype=float64>, 'schizo': <tf.Tensor 'IteratorGetNext:86' shape=(None,) dtype=float64>, 'bipol': <tf.Tensor 'IteratorGetNext:41' shape=(None,) dtype=float64>, 'anx': <tf.Tensor 'IteratorGetNext:39' shape=(None,) dtype=float64>, 'insom': <tf.Tensor 'IteratorGetNext:74' shape=(None,) dtype=float64>, 'alch': <tf.Tensor 'IteratorGetNext:38' shape=(None,) dtype=float64>, 'stress': <tf.Tensor 'IteratorGetNext:93' shape=(None,) dtype=float64>, 'asth2': <tf.Tensor 'IteratorGetNext:40' shape=(None,) dtype=float64>, 'fhtnyn': <tf.Tensor 'IteratorGetNext:63' shape=(None,) dtype=float64>, 'fcvayn': <tf.Tensor 'IteratorGetNext:60' shape=(None,) dtype=float64>, 'flipyn': <tf.Tensor 'IteratorGetNext:66' shape=(None,) dtype=float64>, 'fbipolyn': <tf.Tensor 'IteratorGetNext:59' shape=(None,) dtype=float64>, 'fschizoyn': <tf.Tensor 'IteratorGetNext:67' shape=(None,) dtype=float64>, 'fanxyn': <tf.Tensor 'IteratorGetNext:57' shape=(None,) dtype=float64>, 'finsomyn': <tf.Tensor 'IteratorGetNext:65' shape=(None,) dtype=float64>, 'falchyn': <tf.Tensor 'IteratorGetNext:56' shape=(None,) dtype=float64>, 'fstressyn': <tf.Tensor 'IteratorGetNext:68' shape=(None,) dtype=float64>, 'fdepyn': <tf.Tensor 'IteratorGetNext:61' shape=(None,) dtype=float64>, 'fdmyn': <tf.Tensor 'IteratorGetNext:62' shape=(None,) dtype=float64>, 'fasthyn': <tf.Tensor 'IteratorGetNext:58' shape=(None,) dtype=float64>, 'jb_irelay': <tf.Tensor 'IteratorGetNext:75' shape=(None,) dtype=float64>, 'sd_idr2': <tf.Tensor 'IteratorGetNext:87' shape=(None,) dtype=float64>, 'sd_idr3': <tf.Tensor 'IteratorGetNext:88' shape=(None,) dtype=float64>, 'income': <tf.Tensor 'IteratorGetNext:73' shape=(None,) dtype=float64>, 'edu': <tf.Tensor 'IteratorGetNext:53' shape=(None,) dtype=float64>, 'Coffee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'coff_sugar': <tf.Tensor 'IteratorGetNext:47' shape=(None,) dtype=float64>, 'coff_cream': <tf.Tensor 'IteratorGetNext:46' shape=(None,) dtype=float64>, 'greentea': <tf.Tensor 'IteratorGetNext:69' shape=(None,) dtype=float64>, 'softdrink': <tf.Tensor 'IteratorGetNext:92' shape=(None,) dtype=float64>, 'etcdrink': <tf.Tensor 'IteratorGetNext:54' shape=(None,) dtype=float64>, 'menyn': <tf.Tensor 'IteratorGetNext:82' shape=(None,) dtype=float64>, 'hrtyn': <tf.Tensor 'IteratorGetNext:70' shape=(None,) dtype=float64>, 'exerfq': <tf.Tensor 'IteratorGetNext:55' shape=(None,) dtype=float64>, 'DXA_total_tscore': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'HeartRate': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, 'FVC': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'FEV1': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'FEF25_75': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'PEF': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float64>, 'FVC__exp': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'FEV1__exp': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'FEF25_75__exp': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'PEF__exp': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'Imp_muscle': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'Imp_fat': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=float64>, 'hsCRP': <tf.Tensor 'IteratorGetNext:71' shape=(None,) dtype=float64>, 'FBS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'FBInsulin': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'Hb_A1c': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, 'Protein': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float64>, 'Albumin': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'Creatinine': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'Calcium': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'AST': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'ALT': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'rGTP': <tf.Tensor 'IteratorGetNext:85' shape=(None,) dtype=float64>, 'UricAcid': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float64>, 'TSH': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float64>, 'tCholesterol': <tf.Tensor 'IteratorGetNext:94' shape=(None,) dtype=float64>, 'HDL': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'LDL': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float64>, 'triglyceride': <tf.Tensor 'IteratorGetNext:95' shape=(None,) dtype=float64>, 'WBC': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float64>, 'RBC': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float64>, 'Hemoglobin': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float64>, 'Platelet': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'Height': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, 'Weight': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float64>, 'Waist': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float64>, 'Hip': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'SBP': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float64>, 'DBP': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'ces_dep': <tf.Tensor 'IteratorGetNext:45' shape=(None,) dtype=float64>, 'marry_yn': <tf.Tensor 'IteratorGetNext:81' shape=(None,) dtype=float64>, 'snoring_yn': <tf.Tensor 'IteratorGetNext:91' shape=(None,) dtype=float64>, 'smoker_yn': <tf.Tensor 'IteratorGetNext:90' shape=(None,) dtype=float64>, 'DRINK_yn': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'walk': <tf.Tensor 'IteratorGetNext:96' shape=(None,) dtype=float64>, 'packyear': <tf.Tensor 'IteratorGetNext:83' shape=(None,) dtype=float64>, 'calorie_intake': <tf.Tensor 'IteratorGetNext:43' shape=(None,) dtype=float64>, 'carbo_intake': <tf.Tensor 'IteratorGetNext:44' shape=(None,) dtype=float64>, 'lipid_intake': <tf.Tensor 'IteratorGetNext:78' shape=(None,) dtype=float64>, 'lipid_plant': <tf.Tensor 'IteratorGetNext:79' shape=(None,) dtype=float64>, 'lipid_animal': <tf.Tensor 'IteratorGetNext:77' shape=(None,) dtype=float64>, 'prot_intake': <tf.Tensor 'IteratorGetNext:84' shape=(None,) dtype=float64>, 'fiber_intake': <tf.Tensor 'IteratorGetNext:64' shape=(None,) dtype=float64>, 'bmi': <tf.Tensor 'IteratorGetNext:42' shape=(None,) dtype=float64>, 'lung_risk10': <tf.Tensor 'IteratorGetNext:80' shape=(None,) dtype=float64>, 'colo_risk10': <tf.Tensor 'IteratorGetNext:48' shape=(None,) dtype=float64>, 'dia_risk10': <tf.Tensor 'IteratorGetNext:51' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2538/2538 [==============================] - ETA: 0s - loss: 19.8334 - accuracy: 0.5687WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'IteratorGetNext:89' shape=(None,) dtype=float64>, 'age': <tf.Tensor 'IteratorGetNext:37' shape=(None,) dtype=float64>, 'cva': <tf.Tensor 'IteratorGetNext:49' shape=(None,) dtype=float64>, 'htn': <tf.Tensor 'IteratorGetNext:72' shape=(None,) dtype=float64>, 'lip': <tf.Tensor 'IteratorGetNext:76' shape=(None,) dtype=float64>, 'dm': <tf.Tensor 'IteratorGetNext:52' shape=(None,) dtype=float64>, 'dep': <tf.Tensor 'IteratorGetNext:50' shape=(None,) dtype=float64>, 'schizo': <tf.Tensor 'IteratorGetNext:86' shape=(None,) dtype=float64>, 'bipol': <tf.Tensor 'IteratorGetNext:41' shape=(None,) dtype=float64>, 'anx': <tf.Tensor 'IteratorGetNext:39' shape=(None,) dtype=float64>, 'insom': <tf.Tensor 'IteratorGetNext:74' shape=(None,) dtype=float64>, 'alch': <tf.Tensor 'IteratorGetNext:38' shape=(None,) dtype=float64>, 'stress': <tf.Tensor 'IteratorGetNext:93' shape=(None,) dtype=float64>, 'asth2': <tf.Tensor 'IteratorGetNext:40' shape=(None,) dtype=float64>, 'fhtnyn': <tf.Tensor 'IteratorGetNext:63' shape=(None,) dtype=float64>, 'fcvayn': <tf.Tensor 'IteratorGetNext:60' shape=(None,) dtype=float64>, 'flipyn': <tf.Tensor 'IteratorGetNext:66' shape=(None,) dtype=float64>, 'fbipolyn': <tf.Tensor 'IteratorGetNext:59' shape=(None,) dtype=float64>, 'fschizoyn': <tf.Tensor 'IteratorGetNext:67' shape=(None,) dtype=float64>, 'fanxyn': <tf.Tensor 'IteratorGetNext:57' shape=(None,) dtype=float64>, 'finsomyn': <tf.Tensor 'IteratorGetNext:65' shape=(None,) dtype=float64>, 'falchyn': <tf.Tensor 'IteratorGetNext:56' shape=(None,) dtype=float64>, 'fstressyn': <tf.Tensor 'IteratorGetNext:68' shape=(None,) dtype=float64>, 'fdepyn': <tf.Tensor 'IteratorGetNext:61' shape=(None,) dtype=float64>, 'fdmyn': <tf.Tensor 'IteratorGetNext:62' shape=(None,) dtype=float64>, 'fasthyn': <tf.Tensor 'IteratorGetNext:58' shape=(None,) dtype=float64>, 'jb_irelay': <tf.Tensor 'IteratorGetNext:75' shape=(None,) dtype=float64>, 'sd_idr2': <tf.Tensor 'IteratorGetNext:87' shape=(None,) dtype=float64>, 'sd_idr3': <tf.Tensor 'IteratorGetNext:88' shape=(None,) dtype=float64>, 'income': <tf.Tensor 'IteratorGetNext:73' shape=(None,) dtype=float64>, 'edu': <tf.Tensor 'IteratorGetNext:53' shape=(None,) dtype=float64>, 'Coffee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'coff_sugar': <tf.Tensor 'IteratorGetNext:47' shape=(None,) dtype=float64>, 'coff_cream': <tf.Tensor 'IteratorGetNext:46' shape=(None,) dtype=float64>, 'greentea': <tf.Tensor 'IteratorGetNext:69' shape=(None,) dtype=float64>, 'softdrink': <tf.Tensor 'IteratorGetNext:92' shape=(None,) dtype=float64>, 'etcdrink': <tf.Tensor 'IteratorGetNext:54' shape=(None,) dtype=float64>, 'menyn': <tf.Tensor 'IteratorGetNext:82' shape=(None,) dtype=float64>, 'hrtyn': <tf.Tensor 'IteratorGetNext:70' shape=(None,) dtype=float64>, 'exerfq': <tf.Tensor 'IteratorGetNext:55' shape=(None,) dtype=float64>, 'DXA_total_tscore': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'HeartRate': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, 'FVC': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'FEV1': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'FEF25_75': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'PEF': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float64>, 'FVC__exp': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'FEV1__exp': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'FEF25_75__exp': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'PEF__exp': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'Imp_muscle': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'Imp_fat': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=float64>, 'hsCRP': <tf.Tensor 'IteratorGetNext:71' shape=(None,) dtype=float64>, 'FBS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'FBInsulin': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'Hb_A1c': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, 'Protein': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float64>, 'Albumin': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'Creatinine': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'Calcium': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'AST': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'ALT': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'rGTP': <tf.Tensor 'IteratorGetNext:85' shape=(None,) dtype=float64>, 'UricAcid': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float64>, 'TSH': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float64>, 'tCholesterol': <tf.Tensor 'IteratorGetNext:94' shape=(None,) dtype=float64>, 'HDL': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'LDL': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float64>, 'triglyceride': <tf.Tensor 'IteratorGetNext:95' shape=(None,) dtype=float64>, 'WBC': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float64>, 'RBC': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float64>, 'Hemoglobin': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float64>, 'Platelet': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'Height': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, 'Weight': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float64>, 'Waist': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float64>, 'Hip': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'SBP': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float64>, 'DBP': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'ces_dep': <tf.Tensor 'IteratorGetNext:45' shape=(None,) dtype=float64>, 'marry_yn': <tf.Tensor 'IteratorGetNext:81' shape=(None,) dtype=float64>, 'snoring_yn': <tf.Tensor 'IteratorGetNext:91' shape=(None,) dtype=float64>, 'smoker_yn': <tf.Tensor 'IteratorGetNext:90' shape=(None,) dtype=float64>, 'DRINK_yn': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'walk': <tf.Tensor 'IteratorGetNext:96' shape=(None,) dtype=float64>, 'packyear': <tf.Tensor 'IteratorGetNext:83' shape=(None,) dtype=float64>, 'calorie_intake': <tf.Tensor 'IteratorGetNext:43' shape=(None,) dtype=float64>, 'carbo_intake': <tf.Tensor 'IteratorGetNext:44' shape=(None,) dtype=float64>, 'lipid_intake': <tf.Tensor 'IteratorGetNext:78' shape=(None,) dtype=float64>, 'lipid_plant': <tf.Tensor 'IteratorGetNext:79' shape=(None,) dtype=float64>, 'lipid_animal': <tf.Tensor 'IteratorGetNext:77' shape=(None,) dtype=float64>, 'prot_intake': <tf.Tensor 'IteratorGetNext:84' shape=(None,) dtype=float64>, 'fiber_intake': <tf.Tensor 'IteratorGetNext:64' shape=(None,) dtype=float64>, 'bmi': <tf.Tensor 'IteratorGetNext:42' shape=(None,) dtype=float64>, 'lung_risk10': <tf.Tensor 'IteratorGetNext:80' shape=(None,) dtype=float64>, 'colo_risk10': <tf.Tensor 'IteratorGetNext:48' shape=(None,) dtype=float64>, 'dia_risk10': <tf.Tensor 'IteratorGetNext:51' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "2538/2538 [==============================] - 56s 20ms/step - loss: 19.8334 - accuracy: 0.5687 - val_loss: 0.9260 - val_accuracy: 0.6400\n",
      "Epoch 2/5\n",
      "2538/2538 [==============================] - 53s 20ms/step - loss: 0.7025 - accuracy: 0.6451 - val_loss: 0.5794 - val_accuracy: 0.6568\n",
      "Epoch 3/5\n",
      "2538/2538 [==============================] - 53s 20ms/step - loss: 0.5550 - accuracy: 0.7016 - val_loss: 0.5015 - val_accuracy: 0.7905\n",
      "Epoch 4/5\n",
      "2538/2538 [==============================] - 53s 20ms/step - loss: 0.5160 - accuracy: 0.7373 - val_loss: 0.4766 - val_accuracy: 0.7953\n",
      "Epoch 5/5\n",
      "2538/2538 [==============================] - 53s 20ms/step - loss: 0.4806 - accuracy: 0.7596 - val_loss: 0.4593 - val_accuracy: 0.7714\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'IteratorGetNext:89' shape=(None,) dtype=float64>, 'age': <tf.Tensor 'IteratorGetNext:37' shape=(None,) dtype=float64>, 'cva': <tf.Tensor 'IteratorGetNext:49' shape=(None,) dtype=float64>, 'htn': <tf.Tensor 'IteratorGetNext:72' shape=(None,) dtype=float64>, 'lip': <tf.Tensor 'IteratorGetNext:76' shape=(None,) dtype=float64>, 'dm': <tf.Tensor 'IteratorGetNext:52' shape=(None,) dtype=float64>, 'dep': <tf.Tensor 'IteratorGetNext:50' shape=(None,) dtype=float64>, 'schizo': <tf.Tensor 'IteratorGetNext:86' shape=(None,) dtype=float64>, 'bipol': <tf.Tensor 'IteratorGetNext:41' shape=(None,) dtype=float64>, 'anx': <tf.Tensor 'IteratorGetNext:39' shape=(None,) dtype=float64>, 'insom': <tf.Tensor 'IteratorGetNext:74' shape=(None,) dtype=float64>, 'alch': <tf.Tensor 'IteratorGetNext:38' shape=(None,) dtype=float64>, 'stress': <tf.Tensor 'IteratorGetNext:93' shape=(None,) dtype=float64>, 'asth2': <tf.Tensor 'IteratorGetNext:40' shape=(None,) dtype=float64>, 'fhtnyn': <tf.Tensor 'IteratorGetNext:63' shape=(None,) dtype=float64>, 'fcvayn': <tf.Tensor 'IteratorGetNext:60' shape=(None,) dtype=float64>, 'flipyn': <tf.Tensor 'IteratorGetNext:66' shape=(None,) dtype=float64>, 'fbipolyn': <tf.Tensor 'IteratorGetNext:59' shape=(None,) dtype=float64>, 'fschizoyn': <tf.Tensor 'IteratorGetNext:67' shape=(None,) dtype=float64>, 'fanxyn': <tf.Tensor 'IteratorGetNext:57' shape=(None,) dtype=float64>, 'finsomyn': <tf.Tensor 'IteratorGetNext:65' shape=(None,) dtype=float64>, 'falchyn': <tf.Tensor 'IteratorGetNext:56' shape=(None,) dtype=float64>, 'fstressyn': <tf.Tensor 'IteratorGetNext:68' shape=(None,) dtype=float64>, 'fdepyn': <tf.Tensor 'IteratorGetNext:61' shape=(None,) dtype=float64>, 'fdmyn': <tf.Tensor 'IteratorGetNext:62' shape=(None,) dtype=float64>, 'fasthyn': <tf.Tensor 'IteratorGetNext:58' shape=(None,) dtype=float64>, 'jb_irelay': <tf.Tensor 'IteratorGetNext:75' shape=(None,) dtype=float64>, 'sd_idr2': <tf.Tensor 'IteratorGetNext:87' shape=(None,) dtype=float64>, 'sd_idr3': <tf.Tensor 'IteratorGetNext:88' shape=(None,) dtype=float64>, 'income': <tf.Tensor 'IteratorGetNext:73' shape=(None,) dtype=float64>, 'edu': <tf.Tensor 'IteratorGetNext:53' shape=(None,) dtype=float64>, 'Coffee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'coff_sugar': <tf.Tensor 'IteratorGetNext:47' shape=(None,) dtype=float64>, 'coff_cream': <tf.Tensor 'IteratorGetNext:46' shape=(None,) dtype=float64>, 'greentea': <tf.Tensor 'IteratorGetNext:69' shape=(None,) dtype=float64>, 'softdrink': <tf.Tensor 'IteratorGetNext:92' shape=(None,) dtype=float64>, 'etcdrink': <tf.Tensor 'IteratorGetNext:54' shape=(None,) dtype=float64>, 'menyn': <tf.Tensor 'IteratorGetNext:82' shape=(None,) dtype=float64>, 'hrtyn': <tf.Tensor 'IteratorGetNext:70' shape=(None,) dtype=float64>, 'exerfq': <tf.Tensor 'IteratorGetNext:55' shape=(None,) dtype=float64>, 'DXA_total_tscore': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'HeartRate': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, 'FVC': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'FEV1': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'FEF25_75': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'PEF': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float64>, 'FVC__exp': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'FEV1__exp': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'FEF25_75__exp': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'PEF__exp': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'Imp_muscle': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'Imp_fat': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=float64>, 'hsCRP': <tf.Tensor 'IteratorGetNext:71' shape=(None,) dtype=float64>, 'FBS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'FBInsulin': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'Hb_A1c': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, 'Protein': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float64>, 'Albumin': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'Creatinine': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'Calcium': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'AST': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'ALT': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'rGTP': <tf.Tensor 'IteratorGetNext:85' shape=(None,) dtype=float64>, 'UricAcid': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float64>, 'TSH': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float64>, 'tCholesterol': <tf.Tensor 'IteratorGetNext:94' shape=(None,) dtype=float64>, 'HDL': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'LDL': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float64>, 'triglyceride': <tf.Tensor 'IteratorGetNext:95' shape=(None,) dtype=float64>, 'WBC': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float64>, 'RBC': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float64>, 'Hemoglobin': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float64>, 'Platelet': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'Height': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, 'Weight': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float64>, 'Waist': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float64>, 'Hip': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'SBP': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float64>, 'DBP': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'ces_dep': <tf.Tensor 'IteratorGetNext:45' shape=(None,) dtype=float64>, 'marry_yn': <tf.Tensor 'IteratorGetNext:81' shape=(None,) dtype=float64>, 'snoring_yn': <tf.Tensor 'IteratorGetNext:91' shape=(None,) dtype=float64>, 'smoker_yn': <tf.Tensor 'IteratorGetNext:90' shape=(None,) dtype=float64>, 'DRINK_yn': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'walk': <tf.Tensor 'IteratorGetNext:96' shape=(None,) dtype=float64>, 'packyear': <tf.Tensor 'IteratorGetNext:83' shape=(None,) dtype=float64>, 'calorie_intake': <tf.Tensor 'IteratorGetNext:43' shape=(None,) dtype=float64>, 'carbo_intake': <tf.Tensor 'IteratorGetNext:44' shape=(None,) dtype=float64>, 'lipid_intake': <tf.Tensor 'IteratorGetNext:78' shape=(None,) dtype=float64>, 'lipid_plant': <tf.Tensor 'IteratorGetNext:79' shape=(None,) dtype=float64>, 'lipid_animal': <tf.Tensor 'IteratorGetNext:77' shape=(None,) dtype=float64>, 'prot_intake': <tf.Tensor 'IteratorGetNext:84' shape=(None,) dtype=float64>, 'fiber_intake': <tf.Tensor 'IteratorGetNext:64' shape=(None,) dtype=float64>, 'bmi': <tf.Tensor 'IteratorGetNext:42' shape=(None,) dtype=float64>, 'lung_risk10': <tf.Tensor 'IteratorGetNext:80' shape=(None,) dtype=float64>, 'colo_risk10': <tf.Tensor 'IteratorGetNext:48' shape=(None,) dtype=float64>, 'dia_risk10': <tf.Tensor 'IteratorGetNext:51' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Confusion Matrix ###\n",
      "[[8555 1105]\n",
      " [3536 7104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79      9660\n",
      "           1       0.87      0.67      0.75     10640\n",
      "\n",
      "    accuracy                           0.77     20300\n",
      "   macro avg       0.79      0.78      0.77     20300\n",
      "weighted avg       0.79      0.77      0.77     20300\n",
      "\n",
      "Accuracy: 0.7714\n",
      "F1 Score: 0.7538\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, history = keras_classifier(df_stat, test_idxs)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy\\n')\n",
    "plt.ylabel(['accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim((0,1))\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXDoMrSFzow0"
   },
   "source": [
    "### 제안 기법 imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 893303,
     "status": "ok",
     "timestamp": 1640671965406,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "SM1cJW5q0Ueo",
    "outputId": "014b9150-e937-4fd0-c25a-947606566b23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [14:12<00:00, 170.49s/it]\n"
     ]
    }
   ],
   "source": [
    "imputer = DSANImputer(rep_dim=16,\n",
    "                      num_heads=4,\n",
    "                      n_hidden=1,\n",
    "                      dropout=0.3,\n",
    "                      lr=3e-3,\n",
    "                      weight_decay=1e-5,\n",
    "                      batch_size=256,\n",
    "                      epochs=5,\n",
    "                      noise_percent=40,\n",
    "                      stopped_epoch=10)\n",
    "\n",
    "cm = CategoryMapper(data=data, num_vars=num_vars, cat_vars=cat_vars)\n",
    "targets = np.isnan(data.values)\n",
    "X_incomplete = cm.fit_transform(data)\n",
    "X_imputed = imputer.fit_transform(data.values, cat_vars=cat_vars)\n",
    "imputed_values = X_incomplete.values\n",
    "imputed_values[targets] = X_imputed[targets]\n",
    "df_imputed = pd.DataFrame(imputed_values, columns=columns)\n",
    "df_imputed = cm.inverse_transform(df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1640671965407,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "L62huSXfmxxr",
    "outputId": "c9cab73b-b4cc-4636-a7ea-3c7700726082"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cva</th>\n",
       "      <th>htn</th>\n",
       "      <th>lip</th>\n",
       "      <th>dm</th>\n",
       "      <th>dep</th>\n",
       "      <th>schizo</th>\n",
       "      <th>bipol</th>\n",
       "      <th>anx</th>\n",
       "      <th>insom</th>\n",
       "      <th>alch</th>\n",
       "      <th>stress</th>\n",
       "      <th>asth2</th>\n",
       "      <th>fhtnyn</th>\n",
       "      <th>fcvayn</th>\n",
       "      <th>flipyn</th>\n",
       "      <th>fbipolyn</th>\n",
       "      <th>fschizoyn</th>\n",
       "      <th>fanxyn</th>\n",
       "      <th>finsomyn</th>\n",
       "      <th>falchyn</th>\n",
       "      <th>fstressyn</th>\n",
       "      <th>fdepyn</th>\n",
       "      <th>fdmyn</th>\n",
       "      <th>fasthyn</th>\n",
       "      <th>jb_irelay</th>\n",
       "      <th>sd_idr2</th>\n",
       "      <th>sd_idr3</th>\n",
       "      <th>income</th>\n",
       "      <th>edu</th>\n",
       "      <th>Coffee</th>\n",
       "      <th>coff_sugar</th>\n",
       "      <th>coff_cream</th>\n",
       "      <th>greentea</th>\n",
       "      <th>softdrink</th>\n",
       "      <th>etcdrink</th>\n",
       "      <th>menyn</th>\n",
       "      <th>hrtyn</th>\n",
       "      <th>exerfq</th>\n",
       "      <th>DXA_total_tscore</th>\n",
       "      <th>HeartRate</th>\n",
       "      <th>FVC</th>\n",
       "      <th>FEV1</th>\n",
       "      <th>FEF25_75</th>\n",
       "      <th>PEF</th>\n",
       "      <th>FVC__exp</th>\n",
       "      <th>FEV1__exp</th>\n",
       "      <th>FEF25_75__exp</th>\n",
       "      <th>PEF__exp</th>\n",
       "      <th>Imp_muscle</th>\n",
       "      <th>Imp_fat</th>\n",
       "      <th>hsCRP</th>\n",
       "      <th>FBS</th>\n",
       "      <th>FBInsulin</th>\n",
       "      <th>Hb_A1c</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>rGTP</th>\n",
       "      <th>UricAcid</th>\n",
       "      <th>TSH</th>\n",
       "      <th>tCholesterol</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>WBC</th>\n",
       "      <th>RBC</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Platelet</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Waist</th>\n",
       "      <th>Hip</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>ces_dep</th>\n",
       "      <th>marry_yn</th>\n",
       "      <th>snoring_yn</th>\n",
       "      <th>smoker_yn</th>\n",
       "      <th>DRINK_yn</th>\n",
       "      <th>walk</th>\n",
       "      <th>packyear</th>\n",
       "      <th>calorie_intake</th>\n",
       "      <th>carbo_intake</th>\n",
       "      <th>lipid_intake</th>\n",
       "      <th>lipid_plant</th>\n",
       "      <th>lipid_animal</th>\n",
       "      <th>prot_intake</th>\n",
       "      <th>fiber_intake</th>\n",
       "      <th>bmi</th>\n",
       "      <th>lung_risk10</th>\n",
       "      <th>colo_risk10</th>\n",
       "      <th>dia_risk10</th>\n",
       "      <th>heart_risk10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.212668</td>\n",
       "      <td>4.363613</td>\n",
       "      <td>407.987030</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.30000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.002310</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.902360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.355376</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>13.1</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.2</td>\n",
       "      <td>40.8</td>\n",
       "      <td>62.8</td>\n",
       "      <td>41.800000</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>323.8</td>\n",
       "      <td>155.9</td>\n",
       "      <td>64.4</td>\n",
       "      <td>69.8</td>\n",
       "      <td>85.6</td>\n",
       "      <td>67.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>228.994232</td>\n",
       "      <td>554.6</td>\n",
       "      <td>309.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.094320</td>\n",
       "      <td>0.175325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.057235</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.929206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.930933</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>23.9</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>110.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>182.1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>122.200000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>493.0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>69.6</td>\n",
       "      <td>82.2</td>\n",
       "      <td>90.4</td>\n",
       "      <td>126.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>186.381653</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>382.8</td>\n",
       "      <td>85.4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163458</td>\n",
       "      <td>0.336127</td>\n",
       "      <td>0.160429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.30000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.959222</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.064203</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>42.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>123.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.722997</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>217.7</td>\n",
       "      <td>64.6</td>\n",
       "      <td>133.2</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>221.6</td>\n",
       "      <td>155.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>64.4</td>\n",
       "      <td>84.6</td>\n",
       "      <td>140.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>217.935455</td>\n",
       "      <td>1131.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>88.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>71.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.081590</td>\n",
       "      <td>0.123890</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.260328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>434.312927</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.06035</td>\n",
       "      <td>0.774574</td>\n",
       "      <td>0.678905</td>\n",
       "      <td>1.049830</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.991602</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.662796</td>\n",
       "      <td>1.720618</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.408350</td>\n",
       "      <td>3.757287</td>\n",
       "      <td>3.542057</td>\n",
       "      <td>8.544281</td>\n",
       "      <td>95.980888</td>\n",
       "      <td>96.100571</td>\n",
       "      <td>101.952934</td>\n",
       "      <td>101.395691</td>\n",
       "      <td>40.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>8.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>171.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>50.400000</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>316.8</td>\n",
       "      <td>177.9</td>\n",
       "      <td>66.3</td>\n",
       "      <td>74.6</td>\n",
       "      <td>96.6</td>\n",
       "      <td>124.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>3516.8</td>\n",
       "      <td>633.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>32.2</td>\n",
       "      <td>73.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.103175</td>\n",
       "      <td>0.236204</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.431331</td>\n",
       "      <td>6.528250</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.70000</td>\n",
       "      <td>0.733505</td>\n",
       "      <td>0.766859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.071770</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.353456</td>\n",
       "      <td>3.647991</td>\n",
       "      <td>3.527552</td>\n",
       "      <td>8.858851</td>\n",
       "      <td>95.489197</td>\n",
       "      <td>99.604156</td>\n",
       "      <td>93.406212</td>\n",
       "      <td>98.075912</td>\n",
       "      <td>24.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>237.7</td>\n",
       "      <td>44.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>127.466064</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>174.0</td>\n",
       "      <td>190.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>93.4</td>\n",
       "      <td>100.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>249.764572</td>\n",
       "      <td>71.4</td>\n",
       "      <td>246.6</td>\n",
       "      <td>142.4</td>\n",
       "      <td>17.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>100.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.026066</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.345936</td>\n",
       "      <td>0.084718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex   age cva htn lip dm dep schizo bipol anx insom alch stress asth2  \\\n",
       "0   2  29.0   1   2   1  1   1      1     1   1     1    1      1     1   \n",
       "1   2  37.0   1   1   1  1   1      1     1   1     1    1      2     1   \n",
       "2   2  32.0   1   1   1  1   1      1     1   1     1    1      1     1   \n",
       "3   1  20.0   1   1   1  1   1      1     1   1     1    1      1     1   \n",
       "4   1  29.0   1   1   1  1   1      1     1   1     1    1      1     2   \n",
       "\n",
       "  fhtnyn fcvayn flipyn fbipolyn fschizoyn fanxyn finsomyn falchyn fstressyn  \\\n",
       "0      1      1      1        1         1      1        1       1         1   \n",
       "1      2      1      1        1         1      1        1       1         1   \n",
       "2      2      1      1        1         1      1        1       1         1   \n",
       "3      1      1      1        1         1      1        1       1         1   \n",
       "4      2      1      1        1         1      1        1       1         1   \n",
       "\n",
       "  fdepyn fdmyn fasthyn jb_irelay   sd_idr2   sd_idr3      income   edu  \\\n",
       "0      1     2       1         1  1.212668  4.363613  407.987030  13.0   \n",
       "1      1     1       1         1  2.000000  5.000000  600.000000  11.0   \n",
       "2      1     1       1         1  1.000000  3.000000  176.000000  19.0   \n",
       "3      1     1       2         1  1.000000  3.000000  434.312927  12.0   \n",
       "4      1     1       1         1  1.431331  6.528250  336.000000  13.0   \n",
       "\n",
       "    Coffee  coff_sugar  coff_cream  greentea  softdrink  etcdrink menyn hrtyn  \\\n",
       "0  1.30000    1.700000    1.100000  1.002310   0.200000  0.902360     2     1   \n",
       "1  0.80000    1.100000    0.500000  1.057235   1.100000  0.929206     1     1   \n",
       "2  1.30000    1.000000    0.200000  0.600000   0.959222  0.600000     1     1   \n",
       "3  1.06035    0.774574    0.678905  1.049830   1.500000  0.991602     1     1   \n",
       "4  0.70000    0.733505    0.766859  1.000000   1.000000  0.900000     1     1   \n",
       "\n",
       "     exerfq  DXA_total_tscore  HeartRate       FVC      FEV1  FEF25_75  \\\n",
       "0  3.000000          1.355376       56.0  4.000000  3.200000  3.400000   \n",
       "1  3.930933          1.400000       61.0  4.800000  3.000000  4.000000   \n",
       "2  4.064203          0.400000       89.0  3.400000  2.200000  4.400000   \n",
       "3  3.662796          1.720618       72.0  4.408350  3.757287  3.542057   \n",
       "4  4.071770          2.800000       85.0  4.353456  3.647991  3.527552   \n",
       "\n",
       "        PEF    FVC__exp   FEV1__exp  FEF25_75__exp    PEF__exp  Imp_muscle  \\\n",
       "0  6.200000   90.000000   99.000000     132.000000   80.000000        13.1   \n",
       "1  6.200000  100.000000   76.000000      66.000000  120.000000        23.9   \n",
       "2  8.400000  119.000000  129.000000      35.000000   55.000000        42.3   \n",
       "3  8.544281   95.980888   96.100571     101.952934  101.395691        40.6   \n",
       "4  8.858851   95.489197   99.604156      93.406212   98.075912        24.6   \n",
       "\n",
       "   Imp_fat  hsCRP    FBS  FBInsulin    Hb_A1c  Protein  Albumin  Creatinine  \\\n",
       "0      9.7    2.0   86.0        2.6  5.500000      8.7      5.5         0.8   \n",
       "1     12.5    0.6  110.0       11.3  5.900000      7.5      4.7         1.2   \n",
       "2      9.5    4.4  123.0        8.4  5.722997      7.6      4.5         0.4   \n",
       "3     11.4    8.0  120.0       13.0  4.300000      8.3      5.0         1.2   \n",
       "4      2.1    3.2  105.0        6.6  5.000000      6.5      4.4         1.0   \n",
       "\n",
       "   Calcium   AST   ALT  rGTP  UricAcid  TSH  tCholesterol   HDL    LDL  \\\n",
       "0     10.8  10.0   9.0  39.6       5.5  1.0         191.2  40.8   62.8   \n",
       "1      8.8  12.0  21.0  11.2       4.6  4.0         182.1  35.0   49.2   \n",
       "2     10.3  22.0  15.0  18.2       3.2  1.2         217.7  64.6  133.2   \n",
       "3     10.0  25.0  19.0  31.6       8.3  1.8         171.4  80.0   63.0   \n",
       "4      9.2  47.0  21.0  19.4       7.1  0.4         237.7  44.6   31.8   \n",
       "\n",
       "   triglyceride  WBC  RBC  Hemoglobin  Platelet  Height  Weight  Waist    Hip  \\\n",
       "0     41.800000  6.6  5.2        12.0     323.8   155.9    64.4   69.8   85.6   \n",
       "1    122.200000  4.2  3.8         8.8     493.0   166.7    69.6   82.2   90.4   \n",
       "2     18.600000  9.6  4.2        12.8     221.6   155.1    43.8   64.4   84.6   \n",
       "3     50.400000  8.2  5.6        14.8     316.8   177.9    66.3   74.6   96.6   \n",
       "4    127.466064  5.4  4.4        16.2     174.0   190.5    77.7   93.4  100.8   \n",
       "\n",
       "     SBP   DBP  ces_dep marry_yn snoring_yn smoker_yn DRINK_yn     walk  \\\n",
       "0   67.0  65.0     25.0        2          2         1        1   1800.0   \n",
       "1  126.0  82.0      9.0        2          2         1        2  16200.0   \n",
       "2  140.0  82.0     19.0        2          1         1        2   1800.0   \n",
       "3  124.0  79.0     11.0        1          1         2        2   6000.0   \n",
       "4   98.0  76.0     20.0        1          1         1        1   1800.0   \n",
       "\n",
       "     packyear  calorie_intake  carbo_intake  lipid_intake  lipid_plant  \\\n",
       "0  228.994232           554.6         309.6          31.8         14.0   \n",
       "1  186.381653          1335.0         382.8          85.4         39.0   \n",
       "2  217.935455          1131.2          41.0          88.4          0.2   \n",
       "3   99.000000          3516.8         633.6           2.6          3.4   \n",
       "4  249.764572            71.4         246.6         142.4         17.6   \n",
       "\n",
       "   lipid_animal  prot_intake  fiber_intake   bmi  lung_risk10  colo_risk10  \\\n",
       "0           8.0         47.0           8.6  26.4     0.000000     0.011559   \n",
       "1          30.4         47.0          65.2  25.0     0.000000     0.163458   \n",
       "2          41.0         71.8           3.6  18.2     0.081590     0.123890   \n",
       "3          32.2         73.0          14.0  21.0     0.103175     0.236204   \n",
       "4          24.6        100.8          18.6  21.4     0.026066     0.007025   \n",
       "\n",
       "   dia_risk10  heart_risk10  \n",
       "0    0.094320      0.175325  \n",
       "1    0.336127      0.160429  \n",
       "2    0.163300      0.260328  \n",
       "3    0.179487      0.242424  \n",
       "4    0.345936      0.084718  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1640671965408,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "mNOlXHtpmv2q",
    "outputId": "763d15d5-1b19-4bbb-fdf2-b9381bf553b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missing Values: 0\n",
      "Missing percent: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "count_mvs(df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 130228,
     "status": "ok",
     "timestamp": 1640672095626,
     "user": {
      "displayName": "DOHOON LEE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgbilawY5M8IhTBJVT0ZHsrfWf7i9EKECyTiPYv=s64",
      "userId": "12016024105431403257"
     },
     "user_tz": -540
    },
    "id": "M1D4bUWgxTFa",
    "outputId": "09572ff8-2d96-4d92-b147-b1df2e9081ce",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'IteratorGetNext:89' shape=(None,) dtype=float64>, 'age': <tf.Tensor 'IteratorGetNext:37' shape=(None,) dtype=float64>, 'cva': <tf.Tensor 'IteratorGetNext:49' shape=(None,) dtype=float64>, 'htn': <tf.Tensor 'IteratorGetNext:72' shape=(None,) dtype=float64>, 'lip': <tf.Tensor 'IteratorGetNext:76' shape=(None,) dtype=float64>, 'dm': <tf.Tensor 'IteratorGetNext:52' shape=(None,) dtype=float64>, 'dep': <tf.Tensor 'IteratorGetNext:50' shape=(None,) dtype=float64>, 'schizo': <tf.Tensor 'IteratorGetNext:86' shape=(None,) dtype=float64>, 'bipol': <tf.Tensor 'IteratorGetNext:41' shape=(None,) dtype=float64>, 'anx': <tf.Tensor 'IteratorGetNext:39' shape=(None,) dtype=float64>, 'insom': <tf.Tensor 'IteratorGetNext:74' shape=(None,) dtype=float64>, 'alch': <tf.Tensor 'IteratorGetNext:38' shape=(None,) dtype=float64>, 'stress': <tf.Tensor 'IteratorGetNext:93' shape=(None,) dtype=float64>, 'asth2': <tf.Tensor 'IteratorGetNext:40' shape=(None,) dtype=float64>, 'fhtnyn': <tf.Tensor 'IteratorGetNext:63' shape=(None,) dtype=float64>, 'fcvayn': <tf.Tensor 'IteratorGetNext:60' shape=(None,) dtype=float64>, 'flipyn': <tf.Tensor 'IteratorGetNext:66' shape=(None,) dtype=float64>, 'fbipolyn': <tf.Tensor 'IteratorGetNext:59' shape=(None,) dtype=float64>, 'fschizoyn': <tf.Tensor 'IteratorGetNext:67' shape=(None,) dtype=float64>, 'fanxyn': <tf.Tensor 'IteratorGetNext:57' shape=(None,) dtype=float64>, 'finsomyn': <tf.Tensor 'IteratorGetNext:65' shape=(None,) dtype=float64>, 'falchyn': <tf.Tensor 'IteratorGetNext:56' shape=(None,) dtype=float64>, 'fstressyn': <tf.Tensor 'IteratorGetNext:68' shape=(None,) dtype=float64>, 'fdepyn': <tf.Tensor 'IteratorGetNext:61' shape=(None,) dtype=float64>, 'fdmyn': <tf.Tensor 'IteratorGetNext:62' shape=(None,) dtype=float64>, 'fasthyn': <tf.Tensor 'IteratorGetNext:58' shape=(None,) dtype=float64>, 'jb_irelay': <tf.Tensor 'IteratorGetNext:75' shape=(None,) dtype=float64>, 'sd_idr2': <tf.Tensor 'IteratorGetNext:87' shape=(None,) dtype=float64>, 'sd_idr3': <tf.Tensor 'IteratorGetNext:88' shape=(None,) dtype=float64>, 'income': <tf.Tensor 'IteratorGetNext:73' shape=(None,) dtype=float64>, 'edu': <tf.Tensor 'IteratorGetNext:53' shape=(None,) dtype=float64>, 'Coffee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'coff_sugar': <tf.Tensor 'IteratorGetNext:47' shape=(None,) dtype=float64>, 'coff_cream': <tf.Tensor 'IteratorGetNext:46' shape=(None,) dtype=float64>, 'greentea': <tf.Tensor 'IteratorGetNext:69' shape=(None,) dtype=float64>, 'softdrink': <tf.Tensor 'IteratorGetNext:92' shape=(None,) dtype=float64>, 'etcdrink': <tf.Tensor 'IteratorGetNext:54' shape=(None,) dtype=float64>, 'menyn': <tf.Tensor 'IteratorGetNext:82' shape=(None,) dtype=float64>, 'hrtyn': <tf.Tensor 'IteratorGetNext:70' shape=(None,) dtype=float64>, 'exerfq': <tf.Tensor 'IteratorGetNext:55' shape=(None,) dtype=float64>, 'DXA_total_tscore': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'HeartRate': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, 'FVC': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'FEV1': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'FEF25_75': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'PEF': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float64>, 'FVC__exp': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'FEV1__exp': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'FEF25_75__exp': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'PEF__exp': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'Imp_muscle': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'Imp_fat': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=float64>, 'hsCRP': <tf.Tensor 'IteratorGetNext:71' shape=(None,) dtype=float64>, 'FBS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'FBInsulin': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'Hb_A1c': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, 'Protein': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float64>, 'Albumin': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'Creatinine': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'Calcium': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'AST': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'ALT': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'rGTP': <tf.Tensor 'IteratorGetNext:85' shape=(None,) dtype=float64>, 'UricAcid': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float64>, 'TSH': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float64>, 'tCholesterol': <tf.Tensor 'IteratorGetNext:94' shape=(None,) dtype=float64>, 'HDL': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'LDL': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float64>, 'triglyceride': <tf.Tensor 'IteratorGetNext:95' shape=(None,) dtype=float64>, 'WBC': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float64>, 'RBC': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float64>, 'Hemoglobin': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float64>, 'Platelet': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'Height': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, 'Weight': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float64>, 'Waist': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float64>, 'Hip': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'SBP': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float64>, 'DBP': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'ces_dep': <tf.Tensor 'IteratorGetNext:45' shape=(None,) dtype=float64>, 'marry_yn': <tf.Tensor 'IteratorGetNext:81' shape=(None,) dtype=float64>, 'snoring_yn': <tf.Tensor 'IteratorGetNext:91' shape=(None,) dtype=float64>, 'smoker_yn': <tf.Tensor 'IteratorGetNext:90' shape=(None,) dtype=float64>, 'DRINK_yn': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'walk': <tf.Tensor 'IteratorGetNext:96' shape=(None,) dtype=float64>, 'packyear': <tf.Tensor 'IteratorGetNext:83' shape=(None,) dtype=float64>, 'calorie_intake': <tf.Tensor 'IteratorGetNext:43' shape=(None,) dtype=float64>, 'carbo_intake': <tf.Tensor 'IteratorGetNext:44' shape=(None,) dtype=float64>, 'lipid_intake': <tf.Tensor 'IteratorGetNext:78' shape=(None,) dtype=float64>, 'lipid_plant': <tf.Tensor 'IteratorGetNext:79' shape=(None,) dtype=float64>, 'lipid_animal': <tf.Tensor 'IteratorGetNext:77' shape=(None,) dtype=float64>, 'prot_intake': <tf.Tensor 'IteratorGetNext:84' shape=(None,) dtype=float64>, 'fiber_intake': <tf.Tensor 'IteratorGetNext:64' shape=(None,) dtype=float64>, 'bmi': <tf.Tensor 'IteratorGetNext:42' shape=(None,) dtype=float64>, 'lung_risk10': <tf.Tensor 'IteratorGetNext:80' shape=(None,) dtype=float64>, 'colo_risk10': <tf.Tensor 'IteratorGetNext:48' shape=(None,) dtype=float64>, 'dia_risk10': <tf.Tensor 'IteratorGetNext:51' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'IteratorGetNext:89' shape=(None,) dtype=float64>, 'age': <tf.Tensor 'IteratorGetNext:37' shape=(None,) dtype=float64>, 'cva': <tf.Tensor 'IteratorGetNext:49' shape=(None,) dtype=float64>, 'htn': <tf.Tensor 'IteratorGetNext:72' shape=(None,) dtype=float64>, 'lip': <tf.Tensor 'IteratorGetNext:76' shape=(None,) dtype=float64>, 'dm': <tf.Tensor 'IteratorGetNext:52' shape=(None,) dtype=float64>, 'dep': <tf.Tensor 'IteratorGetNext:50' shape=(None,) dtype=float64>, 'schizo': <tf.Tensor 'IteratorGetNext:86' shape=(None,) dtype=float64>, 'bipol': <tf.Tensor 'IteratorGetNext:41' shape=(None,) dtype=float64>, 'anx': <tf.Tensor 'IteratorGetNext:39' shape=(None,) dtype=float64>, 'insom': <tf.Tensor 'IteratorGetNext:74' shape=(None,) dtype=float64>, 'alch': <tf.Tensor 'IteratorGetNext:38' shape=(None,) dtype=float64>, 'stress': <tf.Tensor 'IteratorGetNext:93' shape=(None,) dtype=float64>, 'asth2': <tf.Tensor 'IteratorGetNext:40' shape=(None,) dtype=float64>, 'fhtnyn': <tf.Tensor 'IteratorGetNext:63' shape=(None,) dtype=float64>, 'fcvayn': <tf.Tensor 'IteratorGetNext:60' shape=(None,) dtype=float64>, 'flipyn': <tf.Tensor 'IteratorGetNext:66' shape=(None,) dtype=float64>, 'fbipolyn': <tf.Tensor 'IteratorGetNext:59' shape=(None,) dtype=float64>, 'fschizoyn': <tf.Tensor 'IteratorGetNext:67' shape=(None,) dtype=float64>, 'fanxyn': <tf.Tensor 'IteratorGetNext:57' shape=(None,) dtype=float64>, 'finsomyn': <tf.Tensor 'IteratorGetNext:65' shape=(None,) dtype=float64>, 'falchyn': <tf.Tensor 'IteratorGetNext:56' shape=(None,) dtype=float64>, 'fstressyn': <tf.Tensor 'IteratorGetNext:68' shape=(None,) dtype=float64>, 'fdepyn': <tf.Tensor 'IteratorGetNext:61' shape=(None,) dtype=float64>, 'fdmyn': <tf.Tensor 'IteratorGetNext:62' shape=(None,) dtype=float64>, 'fasthyn': <tf.Tensor 'IteratorGetNext:58' shape=(None,) dtype=float64>, 'jb_irelay': <tf.Tensor 'IteratorGetNext:75' shape=(None,) dtype=float64>, 'sd_idr2': <tf.Tensor 'IteratorGetNext:87' shape=(None,) dtype=float64>, 'sd_idr3': <tf.Tensor 'IteratorGetNext:88' shape=(None,) dtype=float64>, 'income': <tf.Tensor 'IteratorGetNext:73' shape=(None,) dtype=float64>, 'edu': <tf.Tensor 'IteratorGetNext:53' shape=(None,) dtype=float64>, 'Coffee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'coff_sugar': <tf.Tensor 'IteratorGetNext:47' shape=(None,) dtype=float64>, 'coff_cream': <tf.Tensor 'IteratorGetNext:46' shape=(None,) dtype=float64>, 'greentea': <tf.Tensor 'IteratorGetNext:69' shape=(None,) dtype=float64>, 'softdrink': <tf.Tensor 'IteratorGetNext:92' shape=(None,) dtype=float64>, 'etcdrink': <tf.Tensor 'IteratorGetNext:54' shape=(None,) dtype=float64>, 'menyn': <tf.Tensor 'IteratorGetNext:82' shape=(None,) dtype=float64>, 'hrtyn': <tf.Tensor 'IteratorGetNext:70' shape=(None,) dtype=float64>, 'exerfq': <tf.Tensor 'IteratorGetNext:55' shape=(None,) dtype=float64>, 'DXA_total_tscore': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'HeartRate': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, 'FVC': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'FEV1': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'FEF25_75': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'PEF': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float64>, 'FVC__exp': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'FEV1__exp': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'FEF25_75__exp': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'PEF__exp': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'Imp_muscle': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'Imp_fat': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=float64>, 'hsCRP': <tf.Tensor 'IteratorGetNext:71' shape=(None,) dtype=float64>, 'FBS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'FBInsulin': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'Hb_A1c': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, 'Protein': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float64>, 'Albumin': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'Creatinine': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'Calcium': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'AST': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'ALT': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'rGTP': <tf.Tensor 'IteratorGetNext:85' shape=(None,) dtype=float64>, 'UricAcid': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float64>, 'TSH': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float64>, 'tCholesterol': <tf.Tensor 'IteratorGetNext:94' shape=(None,) dtype=float64>, 'HDL': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'LDL': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float64>, 'triglyceride': <tf.Tensor 'IteratorGetNext:95' shape=(None,) dtype=float64>, 'WBC': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float64>, 'RBC': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float64>, 'Hemoglobin': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float64>, 'Platelet': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'Height': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, 'Weight': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float64>, 'Waist': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float64>, 'Hip': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'SBP': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float64>, 'DBP': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'ces_dep': <tf.Tensor 'IteratorGetNext:45' shape=(None,) dtype=float64>, 'marry_yn': <tf.Tensor 'IteratorGetNext:81' shape=(None,) dtype=float64>, 'snoring_yn': <tf.Tensor 'IteratorGetNext:91' shape=(None,) dtype=float64>, 'smoker_yn': <tf.Tensor 'IteratorGetNext:90' shape=(None,) dtype=float64>, 'DRINK_yn': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'walk': <tf.Tensor 'IteratorGetNext:96' shape=(None,) dtype=float64>, 'packyear': <tf.Tensor 'IteratorGetNext:83' shape=(None,) dtype=float64>, 'calorie_intake': <tf.Tensor 'IteratorGetNext:43' shape=(None,) dtype=float64>, 'carbo_intake': <tf.Tensor 'IteratorGetNext:44' shape=(None,) dtype=float64>, 'lipid_intake': <tf.Tensor 'IteratorGetNext:78' shape=(None,) dtype=float64>, 'lipid_plant': <tf.Tensor 'IteratorGetNext:79' shape=(None,) dtype=float64>, 'lipid_animal': <tf.Tensor 'IteratorGetNext:77' shape=(None,) dtype=float64>, 'prot_intake': <tf.Tensor 'IteratorGetNext:84' shape=(None,) dtype=float64>, 'fiber_intake': <tf.Tensor 'IteratorGetNext:64' shape=(None,) dtype=float64>, 'bmi': <tf.Tensor 'IteratorGetNext:42' shape=(None,) dtype=float64>, 'lung_risk10': <tf.Tensor 'IteratorGetNext:80' shape=(None,) dtype=float64>, 'colo_risk10': <tf.Tensor 'IteratorGetNext:48' shape=(None,) dtype=float64>, 'dia_risk10': <tf.Tensor 'IteratorGetNext:51' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2538/2538 [==============================] - ETA: 0s - loss: 16.8347 - accuracy: 0.5666WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'IteratorGetNext:89' shape=(None,) dtype=float64>, 'age': <tf.Tensor 'IteratorGetNext:37' shape=(None,) dtype=float64>, 'cva': <tf.Tensor 'IteratorGetNext:49' shape=(None,) dtype=float64>, 'htn': <tf.Tensor 'IteratorGetNext:72' shape=(None,) dtype=float64>, 'lip': <tf.Tensor 'IteratorGetNext:76' shape=(None,) dtype=float64>, 'dm': <tf.Tensor 'IteratorGetNext:52' shape=(None,) dtype=float64>, 'dep': <tf.Tensor 'IteratorGetNext:50' shape=(None,) dtype=float64>, 'schizo': <tf.Tensor 'IteratorGetNext:86' shape=(None,) dtype=float64>, 'bipol': <tf.Tensor 'IteratorGetNext:41' shape=(None,) dtype=float64>, 'anx': <tf.Tensor 'IteratorGetNext:39' shape=(None,) dtype=float64>, 'insom': <tf.Tensor 'IteratorGetNext:74' shape=(None,) dtype=float64>, 'alch': <tf.Tensor 'IteratorGetNext:38' shape=(None,) dtype=float64>, 'stress': <tf.Tensor 'IteratorGetNext:93' shape=(None,) dtype=float64>, 'asth2': <tf.Tensor 'IteratorGetNext:40' shape=(None,) dtype=float64>, 'fhtnyn': <tf.Tensor 'IteratorGetNext:63' shape=(None,) dtype=float64>, 'fcvayn': <tf.Tensor 'IteratorGetNext:60' shape=(None,) dtype=float64>, 'flipyn': <tf.Tensor 'IteratorGetNext:66' shape=(None,) dtype=float64>, 'fbipolyn': <tf.Tensor 'IteratorGetNext:59' shape=(None,) dtype=float64>, 'fschizoyn': <tf.Tensor 'IteratorGetNext:67' shape=(None,) dtype=float64>, 'fanxyn': <tf.Tensor 'IteratorGetNext:57' shape=(None,) dtype=float64>, 'finsomyn': <tf.Tensor 'IteratorGetNext:65' shape=(None,) dtype=float64>, 'falchyn': <tf.Tensor 'IteratorGetNext:56' shape=(None,) dtype=float64>, 'fstressyn': <tf.Tensor 'IteratorGetNext:68' shape=(None,) dtype=float64>, 'fdepyn': <tf.Tensor 'IteratorGetNext:61' shape=(None,) dtype=float64>, 'fdmyn': <tf.Tensor 'IteratorGetNext:62' shape=(None,) dtype=float64>, 'fasthyn': <tf.Tensor 'IteratorGetNext:58' shape=(None,) dtype=float64>, 'jb_irelay': <tf.Tensor 'IteratorGetNext:75' shape=(None,) dtype=float64>, 'sd_idr2': <tf.Tensor 'IteratorGetNext:87' shape=(None,) dtype=float64>, 'sd_idr3': <tf.Tensor 'IteratorGetNext:88' shape=(None,) dtype=float64>, 'income': <tf.Tensor 'IteratorGetNext:73' shape=(None,) dtype=float64>, 'edu': <tf.Tensor 'IteratorGetNext:53' shape=(None,) dtype=float64>, 'Coffee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'coff_sugar': <tf.Tensor 'IteratorGetNext:47' shape=(None,) dtype=float64>, 'coff_cream': <tf.Tensor 'IteratorGetNext:46' shape=(None,) dtype=float64>, 'greentea': <tf.Tensor 'IteratorGetNext:69' shape=(None,) dtype=float64>, 'softdrink': <tf.Tensor 'IteratorGetNext:92' shape=(None,) dtype=float64>, 'etcdrink': <tf.Tensor 'IteratorGetNext:54' shape=(None,) dtype=float64>, 'menyn': <tf.Tensor 'IteratorGetNext:82' shape=(None,) dtype=float64>, 'hrtyn': <tf.Tensor 'IteratorGetNext:70' shape=(None,) dtype=float64>, 'exerfq': <tf.Tensor 'IteratorGetNext:55' shape=(None,) dtype=float64>, 'DXA_total_tscore': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'HeartRate': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, 'FVC': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'FEV1': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'FEF25_75': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'PEF': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float64>, 'FVC__exp': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'FEV1__exp': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'FEF25_75__exp': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'PEF__exp': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'Imp_muscle': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'Imp_fat': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=float64>, 'hsCRP': <tf.Tensor 'IteratorGetNext:71' shape=(None,) dtype=float64>, 'FBS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'FBInsulin': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'Hb_A1c': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, 'Protein': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float64>, 'Albumin': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'Creatinine': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'Calcium': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'AST': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'ALT': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'rGTP': <tf.Tensor 'IteratorGetNext:85' shape=(None,) dtype=float64>, 'UricAcid': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float64>, 'TSH': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float64>, 'tCholesterol': <tf.Tensor 'IteratorGetNext:94' shape=(None,) dtype=float64>, 'HDL': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'LDL': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float64>, 'triglyceride': <tf.Tensor 'IteratorGetNext:95' shape=(None,) dtype=float64>, 'WBC': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float64>, 'RBC': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float64>, 'Hemoglobin': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float64>, 'Platelet': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'Height': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, 'Weight': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float64>, 'Waist': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float64>, 'Hip': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'SBP': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float64>, 'DBP': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'ces_dep': <tf.Tensor 'IteratorGetNext:45' shape=(None,) dtype=float64>, 'marry_yn': <tf.Tensor 'IteratorGetNext:81' shape=(None,) dtype=float64>, 'snoring_yn': <tf.Tensor 'IteratorGetNext:91' shape=(None,) dtype=float64>, 'smoker_yn': <tf.Tensor 'IteratorGetNext:90' shape=(None,) dtype=float64>, 'DRINK_yn': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'walk': <tf.Tensor 'IteratorGetNext:96' shape=(None,) dtype=float64>, 'packyear': <tf.Tensor 'IteratorGetNext:83' shape=(None,) dtype=float64>, 'calorie_intake': <tf.Tensor 'IteratorGetNext:43' shape=(None,) dtype=float64>, 'carbo_intake': <tf.Tensor 'IteratorGetNext:44' shape=(None,) dtype=float64>, 'lipid_intake': <tf.Tensor 'IteratorGetNext:78' shape=(None,) dtype=float64>, 'lipid_plant': <tf.Tensor 'IteratorGetNext:79' shape=(None,) dtype=float64>, 'lipid_animal': <tf.Tensor 'IteratorGetNext:77' shape=(None,) dtype=float64>, 'prot_intake': <tf.Tensor 'IteratorGetNext:84' shape=(None,) dtype=float64>, 'fiber_intake': <tf.Tensor 'IteratorGetNext:64' shape=(None,) dtype=float64>, 'bmi': <tf.Tensor 'IteratorGetNext:42' shape=(None,) dtype=float64>, 'lung_risk10': <tf.Tensor 'IteratorGetNext:80' shape=(None,) dtype=float64>, 'colo_risk10': <tf.Tensor 'IteratorGetNext:48' shape=(None,) dtype=float64>, 'dia_risk10': <tf.Tensor 'IteratorGetNext:51' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "2538/2538 [==============================] - 55s 20ms/step - loss: 16.8347 - accuracy: 0.5666 - val_loss: 0.8765 - val_accuracy: 0.6787\n",
      "Epoch 2/5\n",
      "2538/2538 [==============================] - 52s 20ms/step - loss: 0.6535 - accuracy: 0.6585 - val_loss: 0.5194 - val_accuracy: 0.7635\n",
      "Epoch 3/5\n",
      "2538/2538 [==============================] - 52s 20ms/step - loss: 0.5441 - accuracy: 0.7197 - val_loss: 0.5491 - val_accuracy: 0.7136\n",
      "Epoch 4/5\n",
      "2538/2538 [==============================] - 52s 20ms/step - loss: 0.5162 - accuracy: 0.7422 - val_loss: 0.4523 - val_accuracy: 0.7943\n",
      "Epoch 5/5\n",
      "2538/2538 [==============================] - 53s 20ms/step - loss: 0.5013 - accuracy: 0.7522 - val_loss: 0.4114 - val_accuracy: 0.8250\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'IteratorGetNext:89' shape=(None,) dtype=float64>, 'age': <tf.Tensor 'IteratorGetNext:37' shape=(None,) dtype=float64>, 'cva': <tf.Tensor 'IteratorGetNext:49' shape=(None,) dtype=float64>, 'htn': <tf.Tensor 'IteratorGetNext:72' shape=(None,) dtype=float64>, 'lip': <tf.Tensor 'IteratorGetNext:76' shape=(None,) dtype=float64>, 'dm': <tf.Tensor 'IteratorGetNext:52' shape=(None,) dtype=float64>, 'dep': <tf.Tensor 'IteratorGetNext:50' shape=(None,) dtype=float64>, 'schizo': <tf.Tensor 'IteratorGetNext:86' shape=(None,) dtype=float64>, 'bipol': <tf.Tensor 'IteratorGetNext:41' shape=(None,) dtype=float64>, 'anx': <tf.Tensor 'IteratorGetNext:39' shape=(None,) dtype=float64>, 'insom': <tf.Tensor 'IteratorGetNext:74' shape=(None,) dtype=float64>, 'alch': <tf.Tensor 'IteratorGetNext:38' shape=(None,) dtype=float64>, 'stress': <tf.Tensor 'IteratorGetNext:93' shape=(None,) dtype=float64>, 'asth2': <tf.Tensor 'IteratorGetNext:40' shape=(None,) dtype=float64>, 'fhtnyn': <tf.Tensor 'IteratorGetNext:63' shape=(None,) dtype=float64>, 'fcvayn': <tf.Tensor 'IteratorGetNext:60' shape=(None,) dtype=float64>, 'flipyn': <tf.Tensor 'IteratorGetNext:66' shape=(None,) dtype=float64>, 'fbipolyn': <tf.Tensor 'IteratorGetNext:59' shape=(None,) dtype=float64>, 'fschizoyn': <tf.Tensor 'IteratorGetNext:67' shape=(None,) dtype=float64>, 'fanxyn': <tf.Tensor 'IteratorGetNext:57' shape=(None,) dtype=float64>, 'finsomyn': <tf.Tensor 'IteratorGetNext:65' shape=(None,) dtype=float64>, 'falchyn': <tf.Tensor 'IteratorGetNext:56' shape=(None,) dtype=float64>, 'fstressyn': <tf.Tensor 'IteratorGetNext:68' shape=(None,) dtype=float64>, 'fdepyn': <tf.Tensor 'IteratorGetNext:61' shape=(None,) dtype=float64>, 'fdmyn': <tf.Tensor 'IteratorGetNext:62' shape=(None,) dtype=float64>, 'fasthyn': <tf.Tensor 'IteratorGetNext:58' shape=(None,) dtype=float64>, 'jb_irelay': <tf.Tensor 'IteratorGetNext:75' shape=(None,) dtype=float64>, 'sd_idr2': <tf.Tensor 'IteratorGetNext:87' shape=(None,) dtype=float64>, 'sd_idr3': <tf.Tensor 'IteratorGetNext:88' shape=(None,) dtype=float64>, 'income': <tf.Tensor 'IteratorGetNext:73' shape=(None,) dtype=float64>, 'edu': <tf.Tensor 'IteratorGetNext:53' shape=(None,) dtype=float64>, 'Coffee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'coff_sugar': <tf.Tensor 'IteratorGetNext:47' shape=(None,) dtype=float64>, 'coff_cream': <tf.Tensor 'IteratorGetNext:46' shape=(None,) dtype=float64>, 'greentea': <tf.Tensor 'IteratorGetNext:69' shape=(None,) dtype=float64>, 'softdrink': <tf.Tensor 'IteratorGetNext:92' shape=(None,) dtype=float64>, 'etcdrink': <tf.Tensor 'IteratorGetNext:54' shape=(None,) dtype=float64>, 'menyn': <tf.Tensor 'IteratorGetNext:82' shape=(None,) dtype=float64>, 'hrtyn': <tf.Tensor 'IteratorGetNext:70' shape=(None,) dtype=float64>, 'exerfq': <tf.Tensor 'IteratorGetNext:55' shape=(None,) dtype=float64>, 'DXA_total_tscore': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float64>, 'HeartRate': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float64>, 'FVC': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float64>, 'FEV1': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'FEF25_75': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float64>, 'PEF': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float64>, 'FVC__exp': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'FEV1__exp': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'FEF25_75__exp': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float64>, 'PEF__exp': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float64>, 'Imp_muscle': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float64>, 'Imp_fat': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=float64>, 'hsCRP': <tf.Tensor 'IteratorGetNext:71' shape=(None,) dtype=float64>, 'FBS': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'FBInsulin': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'Hb_A1c': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float64>, 'Protein': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float64>, 'Albumin': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float64>, 'Creatinine': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>, 'Calcium': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float64>, 'AST': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'ALT': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float64>, 'rGTP': <tf.Tensor 'IteratorGetNext:85' shape=(None,) dtype=float64>, 'UricAcid': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float64>, 'TSH': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float64>, 'tCholesterol': <tf.Tensor 'IteratorGetNext:94' shape=(None,) dtype=float64>, 'HDL': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'LDL': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float64>, 'triglyceride': <tf.Tensor 'IteratorGetNext:95' shape=(None,) dtype=float64>, 'WBC': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float64>, 'RBC': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float64>, 'Hemoglobin': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float64>, 'Platelet': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float64>, 'Height': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float64>, 'Weight': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float64>, 'Waist': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float64>, 'Hip': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float64>, 'SBP': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float64>, 'DBP': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'ces_dep': <tf.Tensor 'IteratorGetNext:45' shape=(None,) dtype=float64>, 'marry_yn': <tf.Tensor 'IteratorGetNext:81' shape=(None,) dtype=float64>, 'snoring_yn': <tf.Tensor 'IteratorGetNext:91' shape=(None,) dtype=float64>, 'smoker_yn': <tf.Tensor 'IteratorGetNext:90' shape=(None,) dtype=float64>, 'DRINK_yn': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'walk': <tf.Tensor 'IteratorGetNext:96' shape=(None,) dtype=float64>, 'packyear': <tf.Tensor 'IteratorGetNext:83' shape=(None,) dtype=float64>, 'calorie_intake': <tf.Tensor 'IteratorGetNext:43' shape=(None,) dtype=float64>, 'carbo_intake': <tf.Tensor 'IteratorGetNext:44' shape=(None,) dtype=float64>, 'lipid_intake': <tf.Tensor 'IteratorGetNext:78' shape=(None,) dtype=float64>, 'lipid_plant': <tf.Tensor 'IteratorGetNext:79' shape=(None,) dtype=float64>, 'lipid_animal': <tf.Tensor 'IteratorGetNext:77' shape=(None,) dtype=float64>, 'prot_intake': <tf.Tensor 'IteratorGetNext:84' shape=(None,) dtype=float64>, 'fiber_intake': <tf.Tensor 'IteratorGetNext:64' shape=(None,) dtype=float64>, 'bmi': <tf.Tensor 'IteratorGetNext:42' shape=(None,) dtype=float64>, 'lung_risk10': <tf.Tensor 'IteratorGetNext:80' shape=(None,) dtype=float64>, 'colo_risk10': <tf.Tensor 'IteratorGetNext:48' shape=(None,) dtype=float64>, 'dia_risk10': <tf.Tensor 'IteratorGetNext:51' shape=(None,) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Confusion Matrix ###\n",
      "[[8426 1234]\n",
      " [2319 8321]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.83      9660\n",
      "           1       0.87      0.78      0.82     10640\n",
      "\n",
      "    accuracy                           0.82     20300\n",
      "   macro avg       0.83      0.83      0.82     20300\n",
      "weighted avg       0.83      0.82      0.82     20300\n",
      "\n",
      "Accuracy: 0.825\n",
      "F1 Score: 0.8241\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, history = keras_classifier(df_imputed.astype('float'), test_idxs)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy\\n')\n",
    "plt.ylabel(['accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim((0,1))\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMkL1L3WnI+2h6IQ+kCx6tI",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "missing_value_imputation.ipynb",
   "provenance": [
    {
     "file_id": "13bi_ny3TgzGp52bWJRURTUc3pd8_Fovd",
     "timestamp": 1640669844698
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
